{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T17:32:20.984828Z",
     "start_time": "2020-09-03T17:32:19.772067Z"
    },
    "execution": {
     "iopub.execute_input": "2020-09-27T02:27:40.816656Z",
     "iopub.status.busy": "2020-09-27T02:27:40.815659Z",
     "iopub.status.idle": "2020-09-27T02:27:42.566023Z",
     "shell.execute_reply": "2020-09-27T02:27:42.566023Z",
     "shell.execute_reply.started": "2020-09-27T02:27:40.816656Z"
    }
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from BorutaShap import BorutaShap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T17:32:23.622769Z",
     "start_time": "2020-09-03T17:32:23.615787Z"
    },
    "execution": {
     "iopub.execute_input": "2020-09-26T21:19:41.650225Z",
     "iopub.status.busy": "2020-09-26T21:19:41.650225Z",
     "iopub.status.idle": "2020-09-26T21:19:41.657180Z",
     "shell.execute_reply": "2020-09-26T21:19:41.656181Z",
     "shell.execute_reply.started": "2020-09-26T21:19:41.650225Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_palette(\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T17:32:51.760524Z",
     "start_time": "2020-09-03T17:32:50.145841Z"
    },
    "execution": {
     "iopub.execute_input": "2020-09-27T02:27:45.036409Z",
     "iopub.status.busy": "2020-09-27T02:27:45.035393Z",
     "iopub.status.idle": "2020-09-27T02:27:45.392460Z",
     "shell.execute_reply": "2020-09-27T02:27:45.391463Z",
     "shell.execute_reply.started": "2020-09-27T02:27:45.036409Z"
    }
   },
   "outputs": [],
   "source": [
    "#load initial cleaned data\n",
    "df=pd.read_csv(r\"..\\data\\processed\\prelim_clean2.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T02:27:58.895326Z",
     "iopub.status.busy": "2020-09-27T02:27:58.895326Z",
     "iopub.status.idle": "2020-09-27T04:41:28.280655Z",
     "shell.execute_reply": "2020-09-27T04:41:28.279645Z",
     "shell.execute_reply.started": "2020-09-27T02:27:58.895326Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [2:13:29<00:00, 80.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 attributes confirmed important: ['NACCAGEB', 'MEMORY', 'NACCALZP', 'PROBAD', 'UDSVERTN', 'NACCMOCA', 'CDRSUM', 'NACCETPR', 'BILLS', 'DECCLIN', 'TRAILBLI', 'TRAILALI', 'NACCADMD', 'VEG', 'WEIGHT', 'NACCMMSE', 'REMDATES', 'DECIN', 'MEMUNITS', 'NACCAGE', 'MEMTIME', 'TRAVEL', 'HOMEHOBB', 'TAXES', 'NACCALZD', 'NACCAMD', 'TRAILA', 'UDSBENTD', 'CRAFTDVR', 'NACCAM', 'ANIMALS', 'NACCPPA', 'COGMEM', 'UDSVERFC', 'INDEPEND', 'BIRTHYR', 'MMSEORDA', 'WAIS', 'TRAILB', 'DECAGE', 'LOGIMEM', 'COMMUN', 'PROBADIF', 'CRAFTDRE', 'CRAFTVRS', 'NACCBMI', 'PAYATTN', 'ORIENT', 'NACCNE4S']\n",
      "485 attributes confirmed unimportant: ['TOBAC30', 'ANXSEV', 'GAMES', 'PRIMLANG', 'NACCLIVS', 'DECCLMOT', 'DIGFORSL', 'COGOTHIF', 'CORTDEF', 'STKIMAG', 'NACCTCSF', 'NACCVASD', 'VISCORR', 'RIGDLOLF', 'DROPACT', 'OTHSLEEP', 'BEPERCH', 'EYEPSP', 'BOWLINC', 'HISPOR', 'NACCMCIE', 'MEMPROB', 'TBI', 'COGOTH3F', 'CVDIMAG1', 'MOCAABST', 'CORT', 'HEARWAID', 'MOMODE', 'HYPERT', 'POSTINST', 'CVDIF', 'PSYCDIS', 'HYPCHOL', 'MMSECOMP', 'CORTVISL', 'CVDIMAG4', 'NACCAPSY', 'OTHBIOM', 'TRESTFAC', 'IMAGLINF', 'UDSVERLN', 'DIABTYPE', 'COGMODE', 'BEIRRIT', 'DIABETES', 'B9CHG', 'STROKE', 'NACCC2', 'COGOTH', 'NACCNIHR', 'SPEECH', 'TRACTLHD', 'TPETFTLD', 'AFIBRILL', 'LEGLF', 'PACKSPER', 'DIGIB', 'MOCAFLUE', 'CVPACDEF', 'NACCMRSA', 'HALL', 'BRNINJ', 'IMAGMICH', 'BEVHALL', 'INFWMH', 'MINTTOTS', 'DOWNSIF', 'COMPORT', 'NACCAPOE', 'ARISING', 'NPSYCLOC', 'NACCEPMD', 'MINTPCNC', 'STEPWISE', 'MARISTAT', 'MOCASER7', 'NEOPSTAT', 'PENTAGON', 'SCHIZOP', 'MYOCLLT', 'MOCANAMI', 'MSAIF', 'FOCLSYM', 'UDSVERTI', 'COGATTN', 'FDGAD', 'NACCMDSS', 'URINEINC', 'ALCDEM', 'HALLSEV', 'CVANGIO', 'NACCBEHF', 'RIGDNECK', 'HISPANIC', 'CVDSIGNS', 'NACCMCIL', 'APRAXSP', 'HIPPATR', 'DELIRIF', 'MOMOPARK', 'TRESTRFT', 'ABUSOTHR', 'CORTIF', 'UDSVERLR', 'VASCPSIF', 'MOGAIT', 'NACCLIPL', 'HELPLESS', 'DISNSEV', 'DIGIFLEN', 'POSSTAB', 'APP', 'MOCALOC', 'CONGHRT', 'RIGDUPLF', 'NACCFTD', 'ARTHUNK', 'GAITNPH', 'NACCDBMD', 'SLOWINGR', 'BOSTON', 'NPSYDEV', 'MOCACLON', 'GAIT', 'CRAFTURS', 'TRAUMBRF', 'OTHCOG', 'MMSEORLO', 'COGFLUC', 'INHISP', 'DXMETHOD', 'ARTHRIT', 'BRADYKIN', 'DYSPSP', 'PARKSIGN', 'NPSYLAN', 'SHOPPING', 'LBDEVAL', 'INCALLS', 'CVAFIB', 'CORTVISR', 'OTHPSY', 'APA', 'BEDISIN', 'HYPOSOM', 'ESSTREIF', 'BEDEL', 'AMYLCSF', 'NCOTHR', 'ENERGY', 'NACCLBDM', 'VASCPS', 'DIGBACLS', 'FDGFTLD', 'INVISITS', 'NACCNAPA', 'SOMATIC', 'CBTIA', 'NACCMOTF', 'APNEA', 'NACCADMU', 'MOMOALS', 'MMSEVIS', 'ANGIOCP', 'HAPPY', 'MOCACUBE', 'POSTURE', 'CRAFTCUE', 'NACCC1', 'VISION', 'DEPD', 'HEARING', 'HXHYPER', 'DIGIF', 'ARTUNKN', 'PREVSTK', 'CVCHF', 'NACCMCIV', 'NACCPPME', 'COGJUDG', 'VISWCORR', 'CVBYPASS', 'NACCNURP', 'IRRSEV', 'SATIS', 'INCONTF', 'NACCLBDP', 'FTLDNOIF', 'INSOMN', 'HYPERCHO', 'CANCER', 'NACCANGI', 'COGOTH2F', 'VASCIF', 'EPILEP', 'BPDIAS', 'ANTIENC', 'NACCFTDM', 'HACHIN', 'FTLDMOIF', 'IRR', 'COGVIS', 'SLEEPAP', 'CVOTHR', 'BORED', 'HIVIF', 'MOSLOW', 'DOWNS', 'MOCALAN', 'ANXIETY', 'NACCADEP', 'NACCMOM', 'UDSVERTE', 'WONDRFUL', 'NACCHTNC', 'TRACTRHD', 'ELAT', 'MEDSIF', 'HEIGHT', 'DIGIBLEN', 'MOCADIGI', 'MOCAVIS', 'RESTTRL', 'MOCACLOC', 'ABRUPT', 'INFNETW', 'BEAGIT', 'OTHMUT', 'DEP', 'BEMODE', 'DEPTREAT', 'MOCAREPE', 'SOMATL', 'MEDS', 'AGITSEV', 'DIABET', 'HYPERTEN', 'NITESEV', 'TBIBRIEF', 'DYSILLIF', 'OTHCOND', 'NORMEXAM', 'NPIQINF', 'IMPSUB', 'STAYHOME', 'QUITSMOK', 'FOCLDEF', 'MOCACLOH', 'ALCOCCAS', 'MINTSCNG', 'SLEEPOTH', 'APRAXL', 'FOCLSIGN', 'DISN', 'MOCACOMP', 'CVDIMAG2', 'DEPDSEV', 'APASEV', 'ELATSEV', 'PRION', 'COGLANG', 'UDSVERLC', 'NACCMCII', 'IMAGMWMH', 'BRADY', 'TRAUMCHR', 'DATSCAN', 'SIVDFIND', 'PD', 'EVENTS', 'CVDMOTR', 'PTSD', 'BIPOLAR', 'TBIEXTEN', 'CRAFTDTI', 'NACCFADM', 'SLOWINGL', 'POSSADIF', 'RIGDLORT', 'WRTHLESS', 'MOCARECC', 'THYROID', 'SEIZURES', 'NACCLBDE', 'NACCPDMD', 'ALCOHOL', 'BRNINCTE', 'NACCFAM', 'IMAGMACH', 'NACCEMD', 'PDNORMAL', 'BEAHALL', 'BEOTHR', 'BPSYS', 'FTLDEVAL', 'RACETER', 'OTHNEUR', 'NACCCCBS', 'OTHCOGIF', 'TBIWOLOS', 'RIGIDR', 'STOVE', 'HYCEPH', 'ARTSPIN', 'TAPSLF', 'NEOPIF', 'ANXIET', 'HXSTROKE', 'ANGIOPCI', 'RBD', 'HANDMOVL', 'ARTH', 'APPSEV', 'MINTPCNG', 'CVDMOTL', 'NACCNINR', 'NACCMCIA', 'NACCDIUR', 'MOCAORPL', 'MOCAORCT', 'NACCDAD', 'CORTSENR', 'GAITPSP', 'NACCAAAS', 'COURSE', 'STROKIF', 'MOCALETT', 'RIGIDL', 'CVANGINA', 'AMYLPET', 'DECSUB', 'PPAPHIF', 'CBSTROKE', 'ALCFREQ', 'NACCCOGF', 'RACE', 'INLIVWTH', 'PARK', 'POSSAD', 'HANDALTR', 'SCHIZOIF', 'DYSILL', 'ALCABUSE', 'EMOT', 'BEVWELL', 'EMPTY', 'HOPELESS', 'ALCDEMIF', 'TRESTRHD', 'FRSTCHG', 'RESIDENC', 'MRFTLD', 'PPAPH', 'FTDIF', 'UDSVERFN', 'STROKDEC', 'RESTTRR', 'NACCPCSF', 'CDRGLOB', 'PTSDDXIF', 'DEPIF', 'NOGDS', 'RIGDUPRT', 'MMSELAN', 'COGSTAT', 'MOCAHEAR', 'AXIALPSP', 'MOT', 'NACCAHTN', 'CVD', 'ARTYPE', 'SMOKYRS', 'DECCLCOG', 'TRAUMEXT', 'CVHVALVE', 'PACEMAKE', 'TRAILBRR', 'DIGFORCT', 'NITE', 'BEREM', 'NEOP', 'AFRAID', 'DEP2YRS', 'MINTTOTW', 'BIPOLDIF', 'MYOINF', 'NACCAPSA', 'INRELY', 'BRNINJIF', 'MOCAREGI', 'NACCTBI', 'HEARAID', 'FTLDSUBT', 'CVHATT', 'EPILEPIF', 'ARTHTYPE', 'COGOTHR', 'NACCBETA', 'COGORI', 'CVDCOG', 'TAPSRT', 'VB12DEF', 'NACCFFTD', 'PARKGAIT', 'INCONTU', 'THYDIS', 'HANDED', 'TRESTLFT', 'MOTSEV', 'EYEMOVE', 'CSFTAU', 'ARTHSPIN', 'PSP', 'ANYMEDS', 'POSTCORT', 'PERSCARE', 'NACCNOVS', 'ANGINA', 'JUDGMENT', 'DEPOTHR', 'OCD', 'LEGRT', 'HVALVE', 'BEAPATHY', 'MYOCLRT', 'TOBAC100', 'VASC', 'MOCARECR', 'HIV', 'BETTER', 'AGIT', 'IMPSUBIF', 'ANXIETIF', 'TRESTLHD', 'B12DEF', 'OTHPSYIF', 'IMAGLAC', 'IMAGEWMH', 'SPIRITS', 'DEMUNIF', 'CVDIMAG3', 'STROKMUL', 'CVPACE', 'MEALPREP', 'MOCARECN', 'REMDIS', 'STROKCOG', 'INRELTO', 'TAUPETAD', 'FTLDNOS', 'DIGBACCT', 'MOCAORDY', 'MOFALLS', 'ESSTREM', 'ALSFIND', 'UDSVERNF', 'MINTSCNC', 'FTD', 'MMSELOC', 'SCHIZ', 'MOCATRAI', 'HANDALTL', 'DECCLBE', 'BEDEP', 'DEL', 'NACCAC', 'HRATE', 'NACCPAFF', 'NACCACEI', 'FACEXP', 'DELSEV', 'NACCACSF', 'RACESEC', 'PRIONIF', 'HYCEPHIF', 'NACCNSD', 'NACCGDS', 'PSPCBS', 'HANDMOVR', 'NACCNRYR', 'PDOTHR', 'MOTREM', 'SOMATR', 'GAITDIS']\n",
      "15 tentative attributes remains: ['COGOTH2', 'NACCTMCI', 'MOCATOTS', 'TRAILARR', 'MOCAORDT', 'MOCAORMO', 'UDSBENTC', 'MOCAORYR', 'COGOTH3', 'NACCNMRI', 'CDRLANG', 'EDUC', 'drug_count', 'UDSBENRS', 'DEMUN']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# no model selected default is Random Forest, if classification is True it is a Classification problem\n",
    "Feature_Selector = BorutaShap(importance_measure='shap',\n",
    "                              classification=True)\n",
    "\n",
    "Feature_Selector.fit(X=df.drop(['target'], axis=1), y=df.target, n_trials=100, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T17:34:26.657070Z",
     "iopub.status.busy": "2020-09-27T17:34:26.657070Z",
     "iopub.status.idle": "2020-09-27T17:34:26.667056Z",
     "shell.execute_reply": "2020-09-27T17:34:26.666044Z",
     "shell.execute_reply.started": "2020-09-27T17:34:26.657070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 tentative features are now accepted: ['COGOTH2' 'NACCTMCI' 'MOCATOTS' 'TRAILARR' 'MOCAORDT' 'MOCAORMO'\n",
      " 'MOCAORYR' 'NACCNMRI' 'drug_count' 'UDSBENRS' 'DEMUN']\n",
      "4 tentative features are now rejected: ['UDSBENTC' 'COGOTH3' 'CDRLANG' 'EDUC']\n"
     ]
    }
   ],
   "source": [
    "Feature_Selector.TentativeRoughFix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T17:33:14.047031Z",
     "iopub.status.busy": "2020-09-27T17:33:14.047031Z",
     "iopub.status.idle": "2020-09-27T17:33:16.024746Z",
     "shell.execute_reply": "2020-09-27T17:33:16.023746Z",
     "shell.execute_reply.started": "2020-09-27T17:33:14.047031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtkAAAInCAYAAABN1UX3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAB2VElEQVR4nO3deZwcVbn/8e8zSQCDEECIAkpQggZURIwC3p+KGy4YVhW3IF4BddwRXC4qKkZQruaKOnpRUAElYAhIEK8guwtKEEQhQQMSWY0LBCQsCXl+f5zqTE1PVXWdmuplej7v1yuv9PRUdZ2e7qp66tRznmPuLgAAAAD1Geh2AwAAAIB+Q5ANAAAA1IwgGwAAAKgZQTYAAABQM4JsAAAAoGYE2QAAAEDNCLIBAACAmhFkA0ABM7vNzB4ys3+n/m1Tw2u+oq42ltjeZ8zsjE5tr4iZHWpmv+h2OwCg3QiyAaC1Oe7++NS/u7rZGDOb3M3tVzVe2w0AVRBkA0AFZjbNzE4xs7vN7E4z+7yZTUp+t4OZXWpm/zSzf5jZD8xss+R3p0vaTtLipFf8o2a2l5nd0fT663u7k57ohWZ2hpndL+nQou2XaLub2aCZ/dnMHjCz45I2/9rM7jezs81sg2TZvczsDjP7r+S93GZmb236O5xmZn83sxVm9kkzG0h+d6iZ/dLM5pvZvySdJelbkvZM3vt9yXL7mNl1ybZvN7PPpF5/+6S9bzezvyZtOCb1+0lJ225J3su1ZvaU5HezzOxiM/uXmd1sZm+M+pABYAwIsgGgmu9LWitppqTnStpb0mHJ70zS8ZK2kbSTpKdI+owkuftcSX/VcO/4l0pubz9JCyVtJukHLbZfxqslPU/SHpI+KulkSW9N2vosSW9OLfskSVtK2lbS2yWdbGbPSH73NUnTJD1N0kskHSLpHal1d5d0q6Tpkt4m6d2Sfp28982SZR5M1ttM0j6S3mNm+ze19/9Jeoakl0v6tJntlDx/ZNLW10raVNJ/SlptZhtLuljSD5Ntv1nSkJk9s/yfCACqI8gGgNbOM7P7kn/nmdkTJb1G0ofc/UF3XylpvqQ3SZK7L3f3i939EXf/u6SvKASgY/Frdz/P3dcpBJO52y/pi+5+v7vfKOmPki5y91vdfZWknyoE7mmfSt7PFZJ+IumNSc/5wZI+4e4PuPttkr4saW5qvbvc/WvuvtbdH8pqiLtf7u5/cPd17n6DpDM1+u/1WXd/yN1/L+n3kp6TPH+YpE+6+80e/N7d/ynpdZJuc/fvJtv+naRzJL0+4m8EAJWRHwcAre3v7j9v/GBmL5A0RdLdZtZ4ekDS7cnvp0s6SdKLJG2S/O7eMbbh9tTjGUXbL+lvqccPZfz8pNTP97r7g6mfVyj00m8paYPk5/Tvts1pdyYz213SCQo96BtI2lDSj5oWuyf1eLWkxyePnyLployXnSFp90ZKSmKypNNbtQcA6kBPNgDEu13SI5K2dPfNkn+bunsjFeF4SS5pF3ffVCFNwlLre9PrPShpauOHpId4q6Zl0uu02n7dNk/SLxq2k3SXpH9IWqMQ0KZ/d2dOu7N+lkJKx/mSnuLu0xTyti1juSy3S9oh5/krUn+fzZIUlfeUfF0AGBOCbACI5O53S7pI0pfNbFMzG0gGDjZSHDaR9G9J95nZtpKObnqJvynkMDf8SdJGyQDAKZI+qdCbW3X77fBZM9vAzF6kkIrxI3d/TNLZkuaZ2SZmNkMhR7qoXODfJD25MbAysYmkf7n7w8ldgrdEtOs7ko4zsx0t2MXMniDpAklPN7O5ZjYl+ff8VC43ALQVQTYAVHOIQmrDTQqpIAslbZ387rOSdpO0SiF/eVHTusdL+mSS431Ukgc9qBAw3qnQs32HihVtv273JNu4S2HQ5bvdfVnyu/crtPdWSb9Q6JU+teC1LpV0o6R7zOwfyXODkj5nZg9I+rRC4F7WV5LlL5J0v6RTJD3O3R9QGAz6pqTd90j6ogouXgCgTuaedecOAIBQwk/SGe7+5C43BQDGFXqyAQAAgJoRZAMAAAA1I10EAAAAqBk92QAAAEDNCLIBAACAmvXljI9bbrmlb7/99t1uBgAAAPrYtdde+w93b548TFKfBtnbb7+9lixZ0u1mAAAAoI+Z2Yq835EuAgAAANSMIBsAAACoGUE2AAAAUDOCbAAAAKBmBNkAAABAzQiyAQAAgJoRZAMAAAA1I8gGAAAAakaQDQAAANSMIBsAAACoGUE2AAAAUDOCbAAAAKBmBNkAAABAzQiyAQAAgJoRZAMAAAA1I8gGAAAAakaQDQAAANRscrcb0E7z5s3TsmXLJEkrVqyQJM2YMUOSNGvWLB1zzDFdaxsAAAD6V1/1ZJvZHDM7edWqVaN+t3r1aq1evboLrQIAAMBEY+7e7TbUbvbs2b5kyZIRz82dO1eSdPrpp3ejSQAAAOgzZnatu8/O+l1f9WQDAAAAvaAve7K33XZbf9nLXjbiuaVLl0qSdtpppxHPk5sNAACAKop6svty4OPDDz+sq393tdZuunb9c5MenSRJ+sXyX6x/bvL9ffn2AQAA0GV9G2Wu3XSt7tvjvsJlNrt6s460BQAAABMLOdkAAABAzQiyAQAAgJoRZAMAAAA168uc7EcffVST75/cMud68v2T188ECQAAANSFnmwAAACgZn3Zk73BBhuUri4yY8aMzjQKAAAAE0ZfBtmSRqWLTHow1Ml+bOPHRiwDAAAA1K0vo8yNNtpIe+y2x4jn1s/4OHP0jI8AAABAnfoyyN566611+umnj3hu7ty5kjTqeQAAAKBuDHwEAAAAakaQDQAAANSMIBsAAACoGUE2AAAAUDOCbAAAAKBmfVldZCzmzZunZcuWSdL6KddnzJihWbNm6Zhjjulm0wAAADBOEGQXWL16dbebAAAAgHHI3L3bbajd7NmzfcmSJSN6pddPRrNTmIymTM80tbUBAACQx8yudffZWb+bMD3ZU6dO7XYTAAAAMEH0dZBNDjUAAAC6geoiAAAAQM36uie7Uxq53+lqJFK5vG8AAAD0H4LsGlGNBAAAABJBdi0avdVUIwEAAIBETjYAAABQO3qyE+ma2g2N2tqNHuqGseZaM6skAABAfyPITixbtkxX/+5qrd107frnJj06SZL0i+W/WP/c5Pvr/ZO1M4+bAZkAAADdQZCdsnbTtbpvj/sKl9ns6s3GvJ10gNuJPG4GZAIAAHRWzwfZZvY0ScdImubur+92e8YTBmQCAAB0R1eCbDM7VdLrJK1092elnn+1pK9KmiTpO+5+grvfKumdZrawG23N08kc7ubtkccNAADQ27rVk/09SV+XdFrjCTObJOkbkl4p6Q5J15jZ+e5+U1da2EK3crgl0j8AAAB6XVeCbHe/0sy2b3r6BZKWJz3XMrMFkvaTVCrINrMjJB0hSdttt110m1asWKHJ909umXM9+f7JWrFihWbMmBGdwz2W3u+yedyd7mEHAADAaL2Uk72tpNtTP98haXcze4KkeZKea2afcPfjs1Z295MlnSxJs2fP9nY3torY3u+sgFkqDpq72cMOAACAoJciLct4zt39n5Le3e6Nz5gxQ7evub1Uz3SjFF4VMb3fWQGz1Dpo7lSVFAAAAGTrpSD7DklPSf38ZEl3daktLcWml1TdRpbHNn4sd/mxXAAAAACgHr0UZF8jaUcze6qkOyW9SdJbutukenUiMAcAAED3dauE35mS9pK0pZndIelYdz/FzN4n6WcKJfxOdfcbu9G+MjqRXlJ2G2PdDgAAAOrVreoib855/kJJF1Z9XTObI2nOzJkzq75EW3UiMKe3HAAAoPt6KV1kzNx9saTFs2fPPrwT22sOZic9GAYkpnOmqeIBAAAw8RABVjRr1qxRzzVK6+00c6eWy7ZLp6qkAAAAIB9BdkVZk7gUTRJTVVbqBz3mAAAAvY3IrMNiUkzyesCLesyzJq8BAABAZxFkd1BsiknelOdFPebNs0ACAACg8/oqyO716iKdSjHppMbU741KJY0876KLBAAAgH7XV0F2p6uL9JtGwCxpRNBcJmBevXp19HYIzAEAQL/qqyB7rCjJN6xs0NwIiqv0yMcE5gAAAOPJxIgYS+jVknxVVL1YSPcitzONZSyBOQAAwHhAkJ3ol3zpfrpYAAAAGK8IsvtMv1wsAAAAjGcE2Rgx4LGh0fvdXBKQwYkAAACt9VWQ3esl/BrSQW06mO1WALts2TJd/burtXbTteufm/RoyOP+xfJfrH9uogz6BAAAGKu+iprGYwm/qVOnllqu3YH52k3X6r497itcpnl6dwAAAGTrqyB7vBhrUBwbmDenfkyElA9qcQMAgG4iyB4nxhIYlg3K+xG1uAEAQDcQZNegV3uMy257xYoVo2prZ5l8/2StWLEiaqCkNPa/Q5WZKKnFDQAAuokgu0YTpce47EBJqf7BkvRMAwCA8YAguwbjPcd3xowZun3N7aUGPjZym8sMlGysM1admokSAACgLgTZ6Iher8Wdl5JS1J4qaSwAAGBi6Ksge7zUye5FzTnZkx4M6R+PbfzYiGWqGk+1uKukpJDGAgAA0rof0dRoPNbJ7gWzZs0a9Vyjl3mnmTuNWra5R7qsXq7FXSUlhTQWAACQp6+CbFSTldpQFDRmVRBBb1q5cqWOPPJIzZ8/X1tttVW3mwMAwIQx0O0GAGifoaEhLVmyRENDQ91uCgAAEwo92YhWtq62NFxbuzGIMEavD5bsdStXrtSiRYvk7jrnnHM0ODhIbzYAAB1CkI2eFTtYskpQ3s+B/NDQkNatWydJWrdunYaGhnTsscd2uVUAAEwMBNmIVrautjSytnYVMYMlq1QwGU9VT2ItXrxYa9askSStWbNG559/PkE2AAAdMv4iB/SEMiX/Gst1UpUKJr1c9WQs5syZo4ULF2rNmjWaMmWK9t1339xlGz36ZWuEAwCAYgTZiBZT8q+xfNWyfxPdWCa8GRwc1KJFiyRJAwMDGhwcbLk96n0DAFCPvgqymYxmbNIBXTovuTmgiy35l/49qosNgKdPn64DDzxQCxYs0EEHHVQ46LHxmVLvGwCAevRVkM1kNPWZOnVqra9XtiJJoxpJlXXGkvvdq6pMeJO+WLr11ls1efJk3XTTTZo3bx6pHwAAdEhfBdkYm/EegHUikB+rTuc+P/LII9poo420wQYb1P7aAAAgH0E2xqQRNDaXvWsOGstWJElXI4ldp44guFNapX6MpbQg070DANB9BNmoRd3pJVV0IpCX6gmAWwW//VxaEACAiYAzNMZkvKeYVNGpALhfSwsCADAREGQ3KVthAxMbAXA8anEDACYSguwCvZACAfQbanEDACYCguwm9Kj1ljIzS6bTMmKXryK2IslYcrj7CbW4AQATCUE2elbMzJJZy1ZZvh0YxAgAwMTDWR0dE9vLXGVmybEuX0aViiTkcAMAMLEQZKMj6uiVBgAAGC/6Ksg2szmS5sycObPbTUGTOnql26UTedy9iFxxABPZypUrdeSRR2r+/Pnaaqutut0c9KG+ihzcfbGkxbNnzz68223B+NAvPexZAbNUHDSTKx5QWhCYmIaGhrRkyRINDQ3p2GOP7XZz0If6++wJtNCJHvbYaiRVZAXMUuugmVzxYZQWBNqjF3uMV65cqUWLFsnddc4552hwcLBn2ob+QZCNnjcRJwiKDcxnzJhRKmCWJk7QXNZELi1ILz46oRd7jIeGhrRu3TpJ0rp163qqbegfBNkYV8bjBEFVqpH0uvSFTzpAIzgbn+jFR7v0ao/x4sWLtWbNGknSmjVrdP755xNko3YE2ei4RoDWnC+cF6BNxKBtPAXmBGjj10Tuxe8ELkZ7t8d4zpw5WrhwodasWaMpU6Zo33337XaT0IcIstE147FXGkE6QCgK0MZawYR0BvSLiXox2qs9xoODg1q0aJEkaWBgQIODg11uEfoRQTY6biIGR/1SJjA2aK6rgknZAIWeQ/SSshej/axXe4ynT5+uAw88UAsWLNBBBx3UEyks6D+9f1YHxrl+KRMoVZsifiwVTMaSztCunkMC+fbjDkbntLvyRy/3GA8ODmr58uU91Sb0F4JsoIKYnuleKhPYaFejIkmV7TRLv+fmZTudL97pnsOJmgLQKb329+3V4H8s7Wp35Y9e7jGePn26zjjjjLa8dq9+V9BZBNmoRS/WQW2XfuqZRryJngLQieChEwMyx3JHoteC/4bYdnWq8kc/9RjHnut69buCziDIRi16sQ5qu/TiFPFlq5FIY6tIMmPGDN39z7s16cFJssds1O99kq/v2e521RO0V68FD2MJ/su+l16txlK1XZ2q/NHOHuNOK3uu69XvCjqLIBtj1qt1UFGsykyUjZ75FStWZAYmU6dOHRHcZE313spYK5KgvXo9eIgNmKXefS/t1quVP3oV5zrEIsjGmPVqHVTULzagbQ6Ky6gyuJLAHL0e/PeiKpU/brrpJs2dO1c/+MEPJlw6HOc6xCLIxpjRG9Ie7S7718sT3sRWJIkNzMdDUB6b/kDVE8SqUvnj6KOP1r///W8dddRRuuCCC9rdxJ7CuQ6x+irINrM5kubMnDmz202ZUHq1DmovKjvbZezgymXLlmWmfozXetxVxATmddXvLqvTg+x6KV+a4L93xVb+uOmmm7R8+XJJ0p///GctW7ZsQvVmc65DrL4627r7YkmLZ8+efXi32zKR9HId1F7VarbL2MGV8+bNy3ydVoH5RDaW+t1j0a5BduMhx7iXgn8EMZU/jj766BE/T7Te7MHBQZ199tmSQroI5zq00ldBNrqjF+uglu0x7rR2bTvvdYuCrSr50rGqDK7s1Dqxy49FLwXAMaky0vBdlarpNb303jFaTOWPRi92w5///Od2NKmnufuI/4EiBNmoRa/WQW3VY4yxm0g10vtB2VQZaWS6TCfTa9CbZs6cOSLQ3nHHHbvYms4bGhrSwMCA1q1bp4GBAQY+oiWOiKhFr9VBJdeznDoGVxbVja0yuLJT68QuX2WwZK8OsCyTKiONTJfpVnoNeseJJ56oAw44YP3P//3f/93F1nTe4sWLtXZtuNBcu3Zt1wc+Mt6h9xFkAxWlD3DpwGm8HODqmLlyItWNrTJYsh+rnrTLRH7v48XOO++8vjd7xx13bDnosd+mFu/lgY+Md+hNBNlADXopLaVs8F/HzJUTrW5sld7cXq560kv66b338wXDiSeeqLlz50b1YvdLANhrg/wZ79D7ev9oBXRAXmAq5Z8Ex8OJsd3Bf7vqxra7RngVVQZXVhEbyMcGdJ1SpV3tfu+dSuHppwuGZjvvvLOuvfbaUsv22wRBvTjIH71t/O3hQJv1Uq90FZ0M/ufMmaMFCxbI3WVmtdw+rSONZSLp1YCuE+3q5RSeqjnsvZpn22+pH1X16iB/9CaCbEDjo1e6F73xjW/UmWeeKSmUtDr44IPH/Jp1pLG0Qz/NkNkpnWhXP6fwtCvNotOTI3WiXZ3Sa4P80dsIsgFUdvbZZ48oaXXWWWd1LSe7H1JMOh2ct1M/vfdOXsR0Os+2XZMjjVW/5HFjYiPIBlDZ4sWLRwx87FZJqyrT0PeiTuV9o/dUyWHvtwmCOtGuvN5yKT/1ZTz0sKM3EWQDqKxMSatO9DDHppjMnTu3I+2KTTGpEjj3ao9xL6fX9KIqaSm9mIvfaWPJFa/SW04PO2L0994HoK1albTq1UGMvdquXg1M6WHvjNi0lF7Nxe+G2LQXqXxvea/2/HcCvfhjQ5ANoLJWJa16dRBj1XZV6f1ud495ld7yMgFzo10EzehlvVQmcCzlIcdDMEsvfjyCbABjMlFKWlXp/a6SK94PgXyVdvVqb3mvtquKfp4kpxfUVYmml4LZidyLXweCbABj0kslrdo51X2V3u/YdebNmzfquboDeUmlAmZpbGkpse3q9QC1H/RqTfV+UjWFh2C2P7EnAehL43FSoU4E8mUHfUpjC7Zi27Vs2bLo3vJO9DL3ap58VTFBYEzPt0TvN9CMIBvA+pNp2Snle9V4amu3xPQwN5bv1ZKHVfRqNZZeVLbnWxrbBVkn0lhIlUE3EGQDWG889v4iTpXe8qxey17Qq73M/ZTHXabnW6rW+90IZjuRxkKqDLqBbxMAem16UL/cXeg1/RSYxy7frm00r1MlmO1EOUJKHqLT+irINrM5kubMnDmz200B0KRK0NiJQLPXg9mydxfaOehT6s1p63tVrwbyndLuYLZTqR9VZuEE0vrqiOjuiyUtnj179uHdbguAbFVSUjqRxtJrqTJjCYzrfi+9OnlPP6kSmMcu365tNK/Tbp1K/SDFBGPFNwNAR1QJGjvRk9yJbbS7l1lq7/vo1UmF0B+qDEbtVOoHKSYYC4JsAOigXusxB+rUiUGf/TSwFP2NIBsAIlTple6F3O7xoFN5372aX96r7Wq32DSWKoEzgTm6of/2VqCPdCLNANXRK12fqnnfsYFpp6a6j1WlXb2oE4M++2lgKfW7+xtBNjBOEND1Bk5yccpeKFbJ+64SmHdiqvsqqszcifJ6NTDv9ODKxv7Y6K1vvFcC+PYgyAZ62Hg46K1cuVJHHnmk5s+fr6222qrbzUEPq/tCsRMDMif6oM8yvfiN5VDNWKe6l+J7v1evXl2tsYjCXgFgTIaGhrRkyRINDQ3p2GOP7XZz0GPGw4UissXcKWgsXzWNZaLmo8fK6vmWyvd+N/bHiXSh2E18YwFUtnLlSi1atEjurnPOOUeDg4P0ZgM9LCaYrdKLXyWNpVfz5HtV7FT36J7+/AYC6IihoSGtW7dOkrRu3Tp6s4Ee1quTCvVqnjwwVgTZACpbvHix1qxZI0las2aNzj//fIJsoEf1S355p95HlUly+sVYqp4wuHIYQTaAyubMmaOFCxdqzZo1mjJlivbdd99uNwkTVOPE3hwI5J3YKY/ZH2I/d5RTR9UTBlcSZAMYg8HBQS1atEiSNDAwoMHBwS63CBNdlQom7SiPOZFzhqu+97Fc+LTjM+zVsn+xqvZKV51SnsGVw/pzDwfQEdOnT9eBBx6oBQsW6KCDDmLQI7omtteynb2cncp97sVAvq73XjZopre6tU7X4sYw/qIAxmRwcFDLly+nFxtIdCJnuF8GMbZat05VLkpi1unlqdur9kpjbAiyAYzJ9OnTdcYZZ3S7GcCE0i+DGDulykVJ7DqdDpzR+wiyAQBAX6tyURK7zrJly/oihxv1IcgGAPSUfqkYUWUgH1VPULcqaSyx64yl5F8/I8gGgAmq14PZdlSM6JZeqXpSVa9/VyaKssGv1Nnc77EOruzX2toE2QAwwXUqmFu5cqWOPPJIzZ8/v7ASzXg+qaZVeR+9/t57KfBHOVVKEVZZp47Blf1WW5sgGwAmqE4HdENDQ1qyZImGhoaYGXScqfJdofe7tSqzSpYJfqXxlfvdr7W1CbIBAG23cuVKLVq0SO6uc845R4ODg9RVnyDo/e6+XqypPhHyuAmyAQBtNzQ0pHXr1kmS1q1bR2/2BDAeg6JO68Sskp2oqV5lcOWyZcv0m9/cKPcd1v/ebENJ0tVXP5x67pZKbeoFBNkAgLZbvHix1qxZI0las2aNzj///HEXZJP+gPGol2uqu++gtWtPLFxm8uSjO9Sa+hFkAwBKqxpozpkzRwsXLtSaNWs0ZcoU7bvvvh1pbzuQ/gCM1Ike+fGIIBsAEC020BwcHNSiRYskSQMDAxocHGxHs9qK3uqJKaZ2eS/mPndK7HtfsWKFzP7dsqfa7BatWPH4ehvbIf35SQMA2qJqoDl9+nQdeOCBWrBggQ466CAGPdaINJbOKbq47ETu81i167syHt57NxBkAwA6YnBwUMuXLx+XvdjjQdm7C8wqGafs36Rq7nM3er/rTnmq8t5nzJihu+9+uFRO9owZG429kV1AkA0A6Ijp06frjDPO6HYz+s5YAmPyy7srtge4ueRdrJjvSieCf7NbRqSLmN0lSXLfZsQy0jPHtJ1uIcgGAGACobe6d8T2ADfXj26XsaR/lE1Jyd7GI2EbO6V7rp85blNMCLIBAACwXh1l/1rdJenl0oJ16fkg28w2ljQk6VFJl7v7D7rcJAAAAGTgTsmwrgTZZnaqpNdJWunuz0o9/2pJX5U0SdJ33P0ESQdKWujui83sLEkE2QAAAH2iXyvkDHRpu9+T9Or0E2Y2SdI3JL1G0s6S3mxmO0t6sqTbk8UeEwAAAPrO1KlT+2owbld6st39SjPbvunpF0ha7u63SpKZLZC0n6Q7FALt69W9iwIAACa8lStX6sgjj9T8+fOpdd4lzVU/pPE/6c147q0u0kufwLYa7rGWQnC9u6STJH3dzPaRtDhvZTM7QtIRkrTddtu1sZkAAExMQ0NDWrJkiYaGhnTsscd2uzkTTl6VDSZ+6U29FGRbxnPu7g9Kekerld39ZEknS9Ls2bO95rYBADChrVy5UosWLZK765xzztHg4CC92R2W1+Pbb1U5+kUvpV/cIekpqZ+fLOmuLrUFAACkDA0Nad26dZKkdevWaWhoqMst6l3z5s3T3LlztXTpUi1dulRz587V3LlzNW/evG43rWNWrlypt73tbfr73//e7aZ0TS8F2ddI2tHMnmpmG0h6k6Tzu9wmAAAgafHixVqzZo0kac2aNTr/fE7RrfTbQL4Y6dSiiapbJfzOlLSXpC3N7A5Jx7r7KWb2Pkk/Uyjhd6q739iN9gEAgJHmzJmjhQsXas2aNZoyZYr23XffbjepZ/XrQL6yVq5cqXPOOUfuroULF07Y1KKu9GS7+5vdfWt3n+LuT3b3U5LnL3T3p7v7Du4efU/FzOaY2cmrVq2qv9EAAExgg4ODGhgIYcPAwIAGBwe73CL0qqGhoRF3PSZqb3YvpYuMmbsvdvcjpk2b1u2mAADQV6ZPn64DDzxQZqaDDjpoQvZMtksjh7s5j3u85nD/+Mc/lnuoQeHuOu+887rboC7ppeoiAACghw0ODmr58uXjthe7MbOgpJ6dXbAfcri32WYbLV++fP3P2267bRdb0z0E2QAAoJTp06frjDPO6HYzatFLwWwvBPd1uuuukcXh7rzzzi61pLsIsgEAwITQb8Fsr9pvv/101llnad26dRoYGND+++/f7SZ1RV/lZAMAAKC7BgcHNXly6MedMmXKuE0vGiuCbAAAANRm+vTpOuiggyb8INm+ShcxszmS5sycObPbTQEAAJiwxvsg2Tr0VU82JfwAAAC6rzFIdqL2Ykt9FmQDAAAAvYAgGwAAAKgZQTYAAABQM4JsAAAAoGZ9FWSb2RwzO3nVqlXdbgoAAAAmsL4KsqkuAgAAgF7QV3WyAQAAJoJ58+Zp2bJlkqSlS5dKkubOnatZs2YxfXyPIMgGAAAYx6ZOndrtJiADQTYAAMA4Q2917yPIBgAAwCikpIwNQTYAAAAKkZISr1SQbWYm6a2SnubunzOz7SQ9yd1/29bWAQAAoCvorR6bsiX8hiTtKenNyc8PSPpGW1o0BtTJBgAAQC8oG2Tv7u7vlfSwJLn7vZI2aFurKqJONgAAAHpB2SB7jZlNkuSSZGZbSVrXtlYBAAAA41jZIPskSedKmm5m8yT9QtIX2tYqAAAAYBxrOfDRzAYk/UXSRyW9XJJJ2t/dl7a5bQAAAMC41DLIdvd1ZvZld99T0rIOtAkAAAAY18qmi1xkZgclpfwAAAAAFCg7Gc2RkjaW9JiZPZw85+6+aXuaBQAAAIxfpYJsd9+k3Q0BAAAA+kXpadXNbF9JL05+vNzdL2hPkwAAAIDxrVROtpmdIOmDkm5K/n0wea6nMOMjAAAAeoG5e+uFzG6QtKu7r0t+niTpOnffpc3tq2T27Nm+ZMmSbjcDAAAAfczMrnX32Vm/K1tdRJI2Sz1m3nIAAAAgR9mc7OMlXWdmlylMRvNiSZ9oW6sAAACAcaxsdZEzzexySc9XCLI/5u73tLNhAAAAwHhVduDjAZJWu/v57v5jSQ+b2f5tbRkAAAAwTpXNyT7W3deX7HD3+yQd25YWAQAAAONc2SA7a7nSNbYBAACAiaRskL3EzL5iZjuY2dPMbL6ka9vZMAAAAGC8Khtkv1/So5LOkvQjSQ9Lem+7GgUAAACMZ2Wrizwo6eOSZGabS7rPy8xiAwAAAExAhT3ZZvZpM5uVPN7QzC6VtFzS38zsFZ1oYAymVQcAAEAvaJUucrCkm5PHb0+Wny7pJZK+0MZ2VeLui939iGnTmJASAAAA3dMqyH40lRbyKklnuvtj7r5UVBcBAAAAMrUKsh8xs2eZ2VaSXirpotTvpravWQAAAMD41ao3+oOSFkraStJ8d/+LJJnZayVd1+a2AQAAAONSYZDt7r+RNCvj+QslXdiuRgEAAADjWdk62euZ2QXtaAgAAADQL6KDbEnb1t4KAAAAoI+0qpP9qoynr0t+94a2tAgAAAAY51r1ZF9oZpeZ2frea3f/z+ThJ9rXLAAAAGD8ahVk3yDph5Kuzui5tvY0CQAAABjfWgXZ7u7flvRySR81s++aWaM+thesBwAAAExYpQY+uvufJO0p6W+SrjOz3dvaKgAAAGAcazUZzfqUEHdfK+njZvZ/ks5UmKAGAAAAQJNWQfZnm59w98vN7HmS3tWeJgEAAADjW2G6iLufl/P8ve5+QltaNAZmNsfMTl61alW3mwIAAIAJrMpkND3L3Re7+xHTpk3rdlMAAAAwgfVVkA0AAAD0glY52QAAAEDXzZs3T8uWLdOKFSu0evXqUb+fOnWqZsyYIUmaNWuWjjnmmE43cQSCbAAAAPS8ZcuW6Te/uVHS4yStG/X7++9/THff/bDMbul427IQZAMAAKDnrVixQtJDTc8+kvy/oaSHkgD7oWTZ7iLIBgAAQM/bYosttHr1aj388MNaty70ZD/22GOSpEmTXAMDA9poo40kbawtttiiiy0NCLIBAADQ88477zxJw7nZktb3WM+YMaMwDzudz91YXmpv7ra5e1teuJtmz57tS5Ys6XYzAAAA0CXNwfjq1avXD5icOnXq+v9bBehFzOxad5+d9Tt6sgEAANB3GgMl3XeQ9ERJktldkqRVq7ZJ/pfuuefGtmyfIBsAAAB9J2vwo/s2pZcdK4JsAAAA9KmHmkr6pauRDC8jPb72LRNkAwAAoO+86lWvysjJDmMRp04dSP6fqhkznqlZs2bVvn2CbAAAAPSd9EDGblQXIcgGAABAX+vGFOsDHd8iAAAA0OcIsgEAAICaEWQDAAAANSPIBgAAAGpGkA0AAADUjCAbAAAAqFlfBdlmNsfMTl61alW3mwIAAIAJrK+CbHdf7O5HTJs2rdtNAQAAwATWV0E2AAAA0AsIsgEAAICaEWQDAAAANSPIBgAAAGpGkA0AAADUjCAbAAAAqBlBNgAAAFAzgmwAAACgZgTZAAAAQM0IsgEAAICaEWQDAAAANSPIBgAAAGpGkA0AAADUjCAbAAAAqBlBNgAAAFAzgmwAAACgZgTZAAAAQM0IsgEAAICaEWQDAAAANSPIBgAAAGpGkA0AAADUjCAbAAAAqBlBNgAAAFAzgmwAAACgZgTZAAAAQM0IsgEAAICaEWQDAAAANSPIBgAAAGpGkA0AAADUjCAbAAAAqBlBNgAAAFCzng+yzexpZnaKmS3sdlsAAACAMtoaZJvZqWa20sz+2PT8q83sZjNbbmYfL3oNd7/V3d/ZznYCAAAAdZrc5tf/nqSvSzqt8YSZTZL0DUmvlHSHpGvM7HxJkyQd37T+f7r7yja3EQAAAKhVW4Nsd7/SzLZvevoFkpa7+62SZGYLJO3n7sdLel3VbZnZEZKOkKTtttuu6ssAAAAAY9aNnOxtJd2e+vmO5LlMZvYEM/uWpOea2SfylnP3k919trvP3mqrreprLQAAABCp3ekiWSzjOc9b2N3/Kend7WsOAAAAUK9u9GTfIekpqZ+fLOmuLrQDAAAAaItuBNnXSNrRzJ5qZhtIepOk87vQDgAAAKAt2l3C70xJv5b0DDO7w8ze6e5rJb1P0s8kLZV0trvf2M52AAAAAJ3U7uoib855/kJJF9a9PTObI2nOzJkz635pAAAAoLSen/Exhrsvdvcjpk2b1u2mAAAAYALrqyAbAAAA6AUE2QAAAEDNCLIBAACAmhFkAwAAADXrqyDbzOaY2cmrVq3qdlMAAAAwgfVVkE11EQAAAPSCvgqyAQAAgF5AkA0AAADUjCAbAAAAqBlBNgAAAFAzgmwAAACgZn0VZFPCDwAAAL2gr4JsSvgBAACgF/RVkA0AAAD0AoJsAAAAoGYE2QAAAEDNCLIBAACAmhFkAwAAADUjyAYAAABq1ldBNnWyAQAA0Av6KsimTjYAAAB6QV8F2QAAAEAvIMgGAAAAakaQDQAAANSMIBsAAACoGUE2AAAAUDOCbAAAAKBmBNkAAABAzSZ3uwF1MrM5kubMnDmz200BAADAODVv3jwtW7ZMkrRixQpJ0owZMyRJs2bN0jHHHNPyNfqqJ5vJaAAAAFCn1atXa/Xq1dHr9VVPNgAAADBW6Z7quXPnSpJOP/30qNfoq55sAAAAoBcQZAMAAAA1I8gGAAAAakaQDQAAANSMIBsAAACoGUE2AAAAUDOCbAAAAKBmBNkAAABAzQiyAQAAgJr1VZBtZnPM7ORVq1Z1uykAAACYwPoqyHb3xe5+xLRp07rdFAAAAExgk7vdAAAAAKAXzJs3T8uWLRvx3NKlSyVJc+fOHfH8rFmzCl+LIBsAAACQtGzZMv3mNzfKfYf1z5ltKEm6+uqHU8/d0vK1CLIBAACAhPsOWrv2xMJlJk8+uuXr9FVONgAAANALCLIBAACAmhFkAwAAADUjyAYAAABqRpANAAAA1IwgGwAAAKgZQTYAAABQM4JsAAAAoGYE2QAAAEDNCLIBAACAmvVVkG1mc8zs5FWrVnW7KQAAAJjA+irIdvfF7n7EtGnTut0UAAAATGB9FWQDAAAAvYAgGwAAAKgZQTYAAABQM4JsAAAAoGYE2QAAAEDNCLIBAACAmhFkAwAAADUjyAYAAABqRpANAAAA1IwgGwAAAKjZ5G43AAAAAOgFK1askNm/NXny0YXLmd2iFSseX7gMPdkAAABAzejJBgAAACTNmDFDd9/9sNauPbFwucmTj9aMGRvpqquuyl2GnmwAAACgZgTZAAAAQM0IsgEAAICakZMNAAAAJMxuGVFdxOwuSZL7NiOWkZ5Z+DoE2QAAAICkWbNmjXpu6dJHJEk77bRR6tlnZi6bZu5eZ9t6wuzZs33JkiXdbgYAAADGublz50qSTj/99FG/M7Nr3X121np9lZNtZnPM7ORVq1Z1uykAAACYwPoqyHb3xe5+xLRp07rdFAAAAExgfRVkAwAAAL2AIBsAAACoGUE2AAAAUDOCbAAAAKBmBNkAAABAzQiyAQAAgJoRZAMAAAA1I8gGAAAAakaQDQAAANSMIBsAAACoGUE2AAAAUDOCbAAAAKBmBNkAAABAzQiyAQAAgJoRZAMAAAA1I8gGAAAAakaQDQAAANSMIBsAAACoGUE2AAAAUDOCbAAAAKBmBNkAAABAzQiyAQAAgJoRZAMAAAA1I8gGAAAAakaQDQAAANSMIBsAAACoGUE2AAAAUDOCbAAAAKBmBNkAAABAzQiyAQAAgJr1fJBtZvub2bfN7Mdmtne32wMAAAC00tYg28xONbOVZvbHpudfbWY3m9lyM/t40Wu4+3nufrikQyUd3MbmAgAAALWY3ObX/56kr0s6rfGEmU2S9A1Jr5R0h6RrzOx8SZMkHd+0/n+6+8rk8SeT9QAAAICe1tYg292vNLPtm55+gaTl7n6rJJnZAkn7ufvxkl7X/BpmZpJOkPRTd/9dO9sLAAAAzJs3T8uWLZMkLV26VJI0d+5cSdKsWbN0zDHHtHyNdvdkZ9lW0u2pn++QtHvB8u+X9ApJ08xsprt/K2shMztC0hGStN1229XUVAAAAExkU6dOrbReN4Jsy3jO8xZ295MkndTqRd39ZEknS9Ls2bNzXw8AAAAoUqanupVuVBe5Q9JTUj8/WdJdXWgHAAAA0BbdCLKvkbSjmT3VzDaQ9CZJ53ehHQAAAEBbtLuE35mSfi3pGWZ2h5m9093XSnqfpJ9JWirpbHe/sZ3tAAAAADqp3dVF3pzz/IWSLmzntgEAAIBu6fkZH2OY2RwzO3nVqlXdbgoAAAAmsL4Kst19sbsfMW3atG43BQAAABNYXwXZAAAAQC8gyAYAAABqRpANAAAA1IwgGwAAAKhZXwXZVBcBAABAL+irIJvqIgAAAOgFfRVkAwAAAL2AIBsAAACoGUE2AAAAUDOCbAAAAKBmBNkAAABAzfoqyKaEHwAAAHqBuXu321A7M/u7pBUZv9pS0j8iXy52nU5so8o6/bKNKuvQrt5r10R+71XW6ZdtVFmHdvVeuybye6+yzkRu10R47zPcfavMNdx9wvyTtKTd63RiG73aron83mlX722DdvXeNmhXf7RrIr932tV72+jldvVVuggAAADQCwiyAQAAgJpNtCD75A6s04ltVFmnX7ZRZR3aNTG3UWWdidyuifzeq6wzkds1kd97lXUmcrsm8nvvz4GPAAAAQDdNtJ5sAAAAoO0IsgEAAICaTe52AzA+mdk+kq5y9/vNbEdJn5Nkkj7v7n+MfK0N3f2RdrQTGG/MbBN3f6Db7eglZjbP3Y/pdjtQjpn9Z97v3P3UNm53M0lz3P30dm2jKjOb4u5rut2OsszsOEmZ+cTu/uk2bdO8z3KYJ0yQbWZPlzTg7ssKljnF3d9Z4bV3lbSvpCdKulvSYnf/fdW2Zrz+dnm/c/e/ZiyfuwO4++dytvF1d39f8viT7v755PHp7j43Y5Vj3P2FyePTJX1QoUj7dyS9NG/7qe1tKul1kuYoFHh/Zc5yTyt4L7fmrLObpJvd/UEzmy7pwwoXACe5+10Zy58p6ePunjWBUV772x4ImdlWkt4i6X5JP5H0BUmbSzrB3a9pse5TJD1J0t3ufkfENqdKkruvrtrunNeN/hxT626j4WPVPe7+aMYyz5D0HkmrJJ0t6XhJm0g60d0vbPH6L5T0ZEl/cvfri5btkB9LelnMCmZ2mKQfufsqM9tD4buyTuGi9/KC9Z6ksO89SeHYdbG7/y1n2de5+wXJ49nuviR5/FZ3/0HOOrHHlTzPj1i2se3p7r6yznUi/14vznsdd78yZ53J7r424/knuPs/M56PDoTM7PSCdQ7Ja3PTa7Q6TjyW83xuAFU1MDezrSUdIOk1kv4l6Zd5y2asu22y7uvc/dUl19lA0t6SDsiKF8xscvJ7SfqZpC0kHamwT+9etm0l2jFf0iJ3vyr13IskHejuH85Y/jB3/07yOL0vf8Tdv5yxiZ/nbLplEByznzRZbGZrJV0n6VeSrm51njWz2ZKuc/e871zz8t9Q+I78suw538yOStqzJOv8U7hun100rGdmP5Z0SHLS+bTCQfpehaDjYznrXOrusSe3N0l6q6QvS7pL0raSPiTpTHdfkLH8OknXS7ov/bQkz9t2ss41km5MLa9knVEHJjP7g6QHJZ0r6er079z9ipxtXObuL00er/87pJ9vWv5yd98rCYDOc/cXFC2f/O5JkvZTOAD9W9IzJb3E3R/MWj5Z57vp5if/7y7pGe6eeZFoZr+U9CJ3X2dmF0k6RdLfJX3M3V+Vsfyuko6TtFQhKLk/rz2pddJ/o5YXZ2Z2VdJ+S72Px0l6ortnXkSZ2SWSvi1pmqSPK1yU3C/ph+7+opx1dpB0qqRbFQ5u20raTtI7s4JZM/uWwt9llZkdLumdklZL+rG7fzVnGxtL+rykXRUCOZP0O0nH5n2WsZ+jmX1N0lnu/gszu0HSEklTJK1qBG1Ny18l6WhJmyl83rsq7AM/T10MZrXrVEkPSfq9pBcrBNqZF6LJ8v+RbGeVpNMkfVLhczw5KxBIjj1fTf6++0r6tKRHJf2Pu5+ds43LFE7I1vw7d1+Xs84v3P3/JY9vULh4vU/hgj8z2DOzVyTtOUXD35W3SzrO3S/JWD79nc98nPVeYo4reczsInffO+d3m0t6c/Lj6Qrf92MkbVnzOrF/rzUK+8XPJT2ikcftvM6O9N9oobu/vvn5puVfkvrRJe0k6QOS/lnwuc9oempvSYOS/pAXZFc5TuS8znfc/bCc3709bz13/37G8h9V2GfvlHSOpI9kHd8z1nuGpAMlvUDSLgoX579scR7aROH4+1pJe0g6UdIV7n5zxrKLJF2rcCx6rsK5bkgh0MwMuCoeJ67M+owLno/ef3O2e4G7v67g91H7Scb6kyUdLOkohfPD1BbLf1bheG+S/iDpV+7+k4LlnyrphZL2lDRL0r3u/oYW23hpss5ukjaUtNTdj271XiT174yPCjuAFHrAliv0Yq9/Pmed+yRd2fTvKklXFqxzqaSNmp7bSNKlOcu/QdL3JJ0l6V2Sppd4L8+XNE/SeQo9dLNLrLOjpI8pHHxOarVOur15j5uW/4Gkz0paLOl9yXOPUzhY5W1jjUIJnE2Sn38a8XkOSHq9Qs/ASZJmFix7WfL/EyTd0Oq9pH5/ksIBu9TnXvZ1M9bdJvk8L1MIfsts46rU40sK1lkoaeem53aSdE7O8o39xCT9ufFdTm8vY52vK1zApp97m6Sv1/U5pv/2kn6W9bjgb3VF1vNF35WI5X8taWuFg/OdyXd+QOHA3up9LFO4EzFF0i8KtnGvwnHlsuT/9Y8L1rkq+X+Hpm1eXrDOxZI2a3puM4VgoPR3vkW7Yo8rV6np2Jv8v7RgGz9T6Oh4r8LF0imSnt7ic6yyTuzfa7qkwxWO9d9LvvdTy34f8x7nrPcKSYuS7TyvaNlk+Q0kHZZ8rz4n6Uktlo8+TuS8zkUFv9su71/B53GWpIMkTZV0YYnt35T8jV6Y/NzyHCTpQoXj6lsU7o4VrqPU8TnZ3uQS26hynMiMZQqej95/8/7urX4fs580LXeOpAWSPiHpJZIeV7JNOyvEU1e3+k4qZB2cIOm7kr4l6bASr7+LwoXoycn35/Nl/179nC4yJbml9TJJv/HhHqCi93ydR/SuJB5z94fTT7j7w2aWeevC3X8k6UdmNkXhdsqFZvZzd/943gY8pAZcI0lmtrukb5vZEnc/vGCdP5vZ9xUuHN6s8IVdUvA+tjGzKxUOolulHm+Zs/whkl6tcBK/LHluM0kfKdjG0xRuzX3fzP4laUsz28ALbr9YSCs5TKFnbrGkN3jrnuYHzewdCleqP0peZ7LCgThrG89RuL1+g6RZXi4N5Glm1shDbzyWVHibdjeFtJqNJQ156xzTbZJbqI3PpPF4m4J1NnX3m9JPuPvSpCcmywZmZgp/qz+mvsujelFTnuFNvcnufkZRT1SFz3H9LXMf2Tu1Qc7y6c9jRurxUwu2IUlbN92mbvzN5dm3qB9y97sl3W1mf3L3hyTJzB7OWFZKjjdmtoukFe5+b/Jz0S3E6z3yjpqka8zsNElPl/TVZBubqcXgdne/r/nn8HXIlPWdb/U3jjqueM4dmhYme5KukvSyHubJmbHmdaL+Xh7STr6tcLx+gaT/lfQqhcA7z+OSnrYBSRulH2ctnBzn3qZw+/s9XuKWfPK5vVjSDyXtI+nh5PkBz7lTovzjRN42sr53puLjym0aece2sY5LGnXH1t1fmdyR2E/hImmn5O9xubv/JWcbxyv0Rn/QwliiKUXvI/Frhd7rPRUurIvegyRtmzpWD0g6pPEdyTmmSPnHibzPQ5LOM7NvKvSq361wXjhaoTMuy87JMcKaHu+UtbBlp/iZcr6LaZHHlbT/kzRboRNjc4W7uOcXrWBm/5T0W0lfkfTiongi8VFJ/1RIwfylu9/YYnkpXGj9QaGD6cqSMUJoX4njyrhkZi+X9CmF29mHu/stZjZT0kfd/YicdS6LDbLN7DaF28Yjnpb0NncfdfIxs0mS9pK0v0K+0m8lne0FuUFmtqXCgeTlCgfECxWu2jPz4czsSIWDwt8U8jsv85L5SmVZfH5X8/qN97SPpMd7/i3a+yX9VWFHe0ypfLCCYHYThYuA1ZJOc/fHLOS17+ruo3ZYM/uBpE94U367me3qOTm6TbdpR/CMlJwkuNhC0tcU7qyk38elOduIun2arPNrhR66EU9LOsPd98xY/i0Kgf9USYe6+7XJfjLf3efkbOMSd3952eeT30V9jmb2dYXe4R+mnnubpP9w9/dkLJ/3ebjn5L8m6+X9jd3dm/drmdk9ki5S+Ju+MvX4Fe6+dcbyH1G4zfxESR9094stpFid5u6vyGnTqZ6RBtaKmT1T4SLg1uTnzSQ9wd1vyVl+maQvNT8t6Sh3H3Xijf3OV2EVcrhTx2CTNFep43HBMaLKOrF/r90UOhV2UuidPM+TPPY8NjKtagR3f0fG8n9RSIV7RMP7VCP9MC9d5LLUj83r5KX9RB0nkm24MgLSvHOsmT1f4bz4TIXUvXNa/b2a1t9YIYDe392bj4HNyz5OoZNoX4Vg7vfufmyLdbZX+DxfK+l2hR7TUZ9XxeN29HEiWe/Vkt6ocHftLoVxGf+Xs+yMgnaNij8KvotedHyK3U+a1t1E4WLmhQppTI+0ismSi6UXKtzx30zS3z0jJ71pnQ0UsgqOUrhT8oSi5ZN1Zih02r5X0iR3f26rdaT+DrKjR6NbyIX6d9bvCgKh2GDrn5JuUQh+79HIYCPzKtdCbt91Crf2HlXrAOVWhR2usVzjYFd04M0bOHVczvuolN9lZhsp7AyNARHXSNog78qwyondIgdoWchjfrfC3+kkSc9W6BH4q7sfmrON3PeY9V0xs88oe8CIe0EOcNNrPEXhNtwfCpapdGDMeJ03en4u4DJJzYPDTCGfNa9XJHY/2Ughr+8/NNyb9StJn/Ok97gMa50/eJik072puk36IrLp+agTVbLOJgp3vFYnP28kae+sC77k91UGs1VZJzoYyHiNWZLe7e4fyvn96yStdPffmtkPFfZ7SfqGu5+Tsfz6jg4rmcNtZnsp/73nHSNeopEBZpl1ov5eSS/kEkmNvN30cbvUAMNWivbTgnU+4O4n1bH9drFwx/ZbCgPNinr+s9b9ibvvk/O7mQpplNsqfC4nKPRqvszdL4rYxnRJ+7n7tzN+d4pC6s7FHjFILuM4saHCncm/5yz/Ik8GPZrZpt7iDq+F4g9y9z+Z2QcUAlIpXPzdULKNmytUbxnVAZFapvJxxcwWKNw5+KXCHb1Rg4Az1nmtpP+ncN5ep5CR8JkW29hU0l8Uzim/dPfbWmzjRIWUlEcU8u1/6QUDytP6OV1kVK9dCekrE1f4+xwk6SkKH0qW2KuUIyu8Tt6VbN6JJbeSQ4FDU0HFyUoNnFK4tThmSc/ONxRuCd0t6VmSvqhwZXh9zmqTKmzqSEkXJI+/pOFKDe9UyCVvdorCoKfNJf1CYSDUAe6+qmAbebe1XSGHduSTBTt9HjN7n8Kt4EclXaKwkz9gZmuyenOT7WT1dm2u0EsS4zCFKh1ZPh17Ylfk5+jhdvR/RW4jy4Ytfn+cpMPM7EPunh4k/BaFSjnNXuk5d3AUBj+P0nwB6SGd7H3Kvw2aHtU/X2Egdat7rVUqAVxV8LtRkguSdyj8TYckvTRp1ykFqx2l4ePX1u7+UgupWz9VyL8s296i9/FpSZ90918VLNPsToVg68kKvcwneOtUiynKuSDLWb5VqtIoZnaLQi9pOk2gqJf53crfT/Psr9CZENOu5nOKSfqmpHd5RmqGhcGF71YYqJ2u9vMld/9pzjaa79jOU7hrG6soBeRUhe/k9QoplEPufpDCHalMllHFQ9IzFI7HWb6m8Df+LzO7Q6EAwU/yOpKSbUxWck4xs7IVST6r4XPbeWpdkegrkg5NHr9Z4fs/ReHvnHnXMmlPbPWWy1r8Ppe7v8lCatWOCqk2vy2x2vYKufnHeLle48OLPosc3/WmNMyy+jnIbuQcpTUOVpm9CO7+WUkys2kKeXNzFHbKrJNtwyUaOYJ8/XYUBu00uzHVs/pkT8qrWUhvydTcs2KpskNZ20h6M9Nftock/VHhi5KXS+fJujtIuq/RK2f5OWF5+V15Bx4pBDSvd/c7U209WSGoz+x5UGQwW9Fj7v7LpD2fcvdPtVoh9V3ZTknpRi8olZe6fTpiu5L+y/PL8b3V3fdIejT+6O47Jq/V8tZ8hQNjjCon9qjP0UZWVkinEFzs7qPKPWYEAZJK5Q8uU0iv+aaZLVdIG3pU+UFtOvhOX8zto5wgO1Z6fzezVV6Q7pK1TrJe4TEikf6eN76buysEEFnnhne4+38kt9rvUKjg0+rE46neqM8lT6y17JxdKX5siBQ+k88lFy7HSFp/R8Hzc4xPVRg/8nslwZZCh0qRtl+QKfTe7qlwl/PHCoPoinrz1o8haOb5+b8jxpA0rZNX/vVGhR7G2zS8b+ys8B3K2v53FHJfpykEsLsqqfajcIGV5W6NvGO7i6RdzCzvjm3ePv+4nNeXpDXu3gjcLjaz3LFQKc/zpvQDd7/KzOZlLewhxfB6SZ9J2niApJ+a2f3u/tqcbZyt4YokR2q4IkkdHQ0Nj3f3fzS21ziu5P0NbHT1lg3dPbeXOuU2ReTWN23zfxRSkq6VdLiZzXX397fY3hkK56TB5CL1Wy169Z+f3Plbq9D581l3v7jFNiaZ2WKFztZVkj7lJcs093OQ/ReNPIm0lASYH5Q0U+EgsVeJK6NtFa6+X6EQzF6ggnxpjexZPS31+BiFgD2vbVllh/JOCp9p+nkjhdsp39Vw2apmsQOn0lfXn8x53GyDdIAtSe5+p4X8qDynKwxS+lPjieS2V9FtuNgBWs9MXSTMSD3OvSBLDp7fVapUXhJwZ5bKy7rVnfQwn6dwks/yULLuI2Z2e+r53Pz62AOjZdfMNYW8yDzRJ/bGRUnG9jNPVAqVYRrSbck7ZuXt68tznk81ze+StJ+ZHSrpyiQIqiWPLieNwxSqgJRRuh2Rx4j1dz2SgPdAhY6FSxSOZ1keNTNT2Pf+IGlpI1guCGYftqT2tCcDpJMLwLzv8N6eUfu/iLvfY2aDCsetixR6ghsn9bzevTWpi9uywVbbL8jc/URJslDudP+kbRd4/jgXVwgWSo0qS9yrEOzGrNM4N24i6WseBlP/1PNT0Na4+68lycyWN1IeLH+AsJR/xzZPlX3+eakLN0l6dvKzPCeVUtXursjCYO89FM6V6xRSE/JMc/d5yXo3SdqlRKrEbqn38uzUY897L2Y2yd0fc/f5yc8bKP9u3ysVOmguUrjD+6EW7WnYXdVz63d1972Sx/9bpkNJIcheoHBROlthQG/RndvPS3qVuz+QfEY/U6iIUmRIYZzdCgu5+WcoxFQt9XOQ/bBHTC6S+JPCgfR3Clef+9vwqOC83u8qI8ijJDvdbxVq8R6fHNxyb2/lvO+bLQxeyVvnSGsaOJUYlX6QOEjhYLt+Bqvkdt+xkvKuPLey0bnMrXqpvq7hW1wN9ypcoLwmZ50PKFxtSiNvo+fdUs+7YCjyJYXR/Ot78sxsJ4WR3q16xCRJ7n5vwZ0CqVqvXuyBMe/9bl6wTpUTe57cSUaSgG6g+XFmgzLSZEpa/x7c/XvJrdpvKhyss0SN0Ff+dy73oG4ja6pvVfLkGXWMSNapUrnnEg0HsI07EEXB7NEK1ZSu0HDN3JdIGlXrPPFVM9tC4cR3rrsvbdEeWRhL8xGFk+v7CwL+tEawJY0MUgqDrXZekDUknT0HKhyX/iipKNC4xwvyY3PcV+buSFryvj+WHOM/ZGF8SF4KpVSh2o+7X2HhLvKj7v6QhZr0WyikF2YtH73Pu/tmsesosopHcsG3r0IqxmKFYgu3tdhGdEWSCu/la5LOMbOTNLwvfkAhhTPr9atUb5FXqIaW8oCZvVUhBputnDFyTab58AD5m83sXS2WNw2nY5U5VkghVm50dN2hiPTHfh74+HSlyoClZfU0JutUGdQUNYLchkfemsKO2nicO/LWzOYqjGgeUMhRm+sFI45zXmNHhdsoedUf8m4TyjMG5tlwfuZXkjYdqZBL9znPGRBgZrmjtwt6Oi9PXdm2fD75XZVJhWYpjDZuDMhcVHQr3HImxyh4vrk9GyoM6ntiyYNPaakD46sUelI+pxYHxozXKJr847KsnvmKbc37ez2mcJHwmJqC+Zy7Ao3AdMTTKghMk/We4u63Zzx/dKNXsen56GNE0/rRM8yVYaHyyj6KOEZYhco9Fds2ReF7uI3CvnW1wrnnkZzlG5UfDlDIzbxcIeDOzM80s+MlzXP3Mifkxjovjg00m7/3SY/8NxUGzY0KOC2yEk2yzg0K+cjnKgQq64MAzx5Q/UaFQFzuflPSM/kOhc8/s6fNCqoAlZUEw88o+Eyiq/0kn+NuCgHM7QoDEu+T9BzPmCykyj5vZvsp5CI/lGzn4z4y9SeTDVfxaJwfiqp4vEvh+1p6tlGrOFjQzHZOlin72TfOc9soFEdYWOZCNlm3VPUWi6yG1rTuppKOULhzcoukb3vx2CiZ2VcVUkwagflDnjFhWWr5Vyh0BjY6Mo4r0SHxNoXOwxWSZigM3C51cdvPQXZ0lQWrUJbOIkeQV92ZknVLlR1qOvg0ep3uVhiwNmqGqmSdKrNEbqLhAXkneFJuK4aFkoZz3P28nN9fLOktnhphbWZPVChJlzcV+2WKmDHPzA5R6H3+qsJV6pMVeoDPyftMLL5UXvPn9LBCztpPPGcnTHpvD1cINjZQmMznPIXeylJX4GUPjBnrZeY+J797g4d676UVnBAzK5IkB849FXJmFynM3LimebkS293OI9MPkvXygv/oEfoWOcOcRVbkSNY5UaEn+48KNWZbliYrCITyKr5srJCXvKuGT1C/U8FMn03rb6pwG3eOwuee+f1qWuc5kv5HIS82s+fUqlVWqXIh3vYLMousQmRmjeoW0xSOKdMV0sTOzLvoqPjeo0sr5rxObrUfM7vK3V9kIQXpBnd/VvJ81EV90T5vZlcrXBStNrOtFGbPbfk9TNZ9ipJSeV48/ubxCvvJc1RyP7EKFUksjGcyRXz2TetXuuC3guotye+jqqEl62yX93pljt8WplbfQdKtnj/GaUyS7+VWCiUCy/aA92+QXYVVmzY46kBa5ctkYeTxpHTPT7Ij7+mtE/ZLS3q7G8HAnQo1OjN75S1MM/ophdvelyqM8L9JYSakzCtPC3VQP6qw031eobblIQqzgH0mZ53nKtzmulQjbze/3/NrWN+rsJM3LjDUeJz1OVq4lf0yT9UST/7mlxb0iERfxMUys/9WqIH7Px7ysjeU9GGFWULzqtQ0ApMH3P1WC7fetlAI/u/NWDbre22SvujumSkTVmGK+KqSz/8AhV6RvyrcYSgM8C2k7Ryg0Hv6QMzFReo18oLsCxQq8fwjudBqjND/kGfXC06ncfzKQhpHXppTY53LFXo71zYCjOT7+NOCC5+XKfTiPF9htP09CoOvfuvui3PWiS11+fXk9U5LPfc2SXvk9RxZyC3eT6Hm7b8V8jRfUhSUm9kLFT6/FynkdJ6rMNNnXs93+mJhRDWWgg6C65VT6clzyrUWtDfvu5Jbpi+vF8zyB4TmdRCsD0AtlG59dqsLHjO7T2HirRFPq7gHOL2dUqUVc16n6OI93TlySfJ4QOECu3AbZff5jA6YxnYsL3CyMCHQyQo9v3coVBvbRtIRnnFXvOJ+sqtCHvMrk22UqUhS5bOPnlI+4zVy73Imv69yF6NxPt1W4ULmhqR99xR8X6L2L8suPtBYPi++ay4ikV6n1Hm+b3Oyc3rOag8EPCTC76rQc/REhUBwseePPL1N8SNvT1UouZQOeJ+hMInCqCDb8mtef94Lajt63CyRb5R0sA/3MO9jZnMUBvfkVZKYL+lghR62yxSmTv1/RVeF7n5dEtDvqbDz3agwGrioV/P62J4ab5qsJwlwipYflQ9oBaXyLNzxuF7hb7v+aeUE/ond0r9LgowTbORkEs3b+b5Cr8YmSU/NeQo57Gcq3AVplvdZZQZmSTvWr2NhwoT3KlwwfaugXaPKYJnZiyQd6AUTBySf/42SfqOQdztPySyeTa//AoWT7LMVDtAv8hKzB+b0gprC4OcsUSP0VW2GOfe4ihyNwPDSpC0zkm2+RyHnOjM1QfGlLqNn+lS47f9dhQuTB5KLjKIA+3cKA8TOVbiV/1jy/FM0nBM5gleoxqLQ+/f/pFF3u+qsWjRfYRDeeSo3U6AUgr7MFAhl571vnhwfBxTK5e1uw7m8ee/jupjAOBE1+M+qV/tp5Pw3P87aRqV9XiPHFUjh8y4aV/B1hfE36wdUJvvyN5Q9Lih6P/FqFUmiPnuLHLdR8BkWVW+pVOnIhwdhL1IY/PiYhbvcmXfuUm2RQlrkAwoVSZ6rsG+PCrJTFyTHK6TIXauQnrR/wTY+k/x/pMId/sY2/qNgnRH6NsiuEggoflCTzOxNCmkDX1a40t1WoZzUme6+IGOVKiNvZzQv42HGrbxe9EM9sua1jZ4l8uXNgWfT9rPqNF+l4gFzj3ioLnKnmd3sGZN9ZLSrkcJzZdLz1ghqimaWHJF7bCFXbW+F2tfvzFj+QgsDW/5b4TNsDGzJKzWVfu2ypfIOVsiZfZzCQf1cb52zN9nMNvJU2UULKUNFgy62Sx1MrnX3bySP8y7gjmvRhkwWP0V8VBksC6kFcxR6QbdRuJj8kOdPmvBzhRHm/+nuK82sbH3dKgMTS4/Qd/fTJZ1uw6let5vZjxUuBPPGKMRW5JCFdKQZCifcvypcHL/WC25rV5AX5OcG/5IaAcP3LUzEtaWZbZjXK+3uuzUem9lOZnaAwgX2/RqdnpX5EiWWkaTbvOQkUKn2xF6QPVHSSxWO97MVSuD9yItz98/1uIliztXwMf1cDV80F10sjJrMycKg9wPdPe94kDcIe6uc5atU/thb4Y5t+ni3kXLGVqnaPh+7DUmamg6wpfUdUnnBZpX9pNGWmIoksZ997AV/1YpNeT3mZQoCbK1QYu96hbS0J+Ut6Ekqp5kd7O7rizqYWavz9ksUSue6mf1W4WI4bxsrktfc1d0/mDz9JwuDW0vp63SRjECgsIeiIGgtyqG7VOFk1rzTXtiqN9VKzmpl+ekMl7j7qFszNpzbtoNCbewXJ88XDRa8VZGzRCbrjQoy3f3knGXvU+hxMA33PrS6TVl1ZslNFK6cX6tw0DpR0hWen5PePD3tOe6ee9C20aXyjvKCW2ip9aYo3BL8nMJt0NzSYWb2KoU6qadp+AJurqTjPX/QzdUKdyEGFHojG4/zcsWr3EK7UvFTxF+R813NfV7hovBcz5kWvGn5DRV6NPZTyJN+hkKuf+nBnsnrFOYpmtlBCp9B8wj9H7j7WSW3MVnSSz0n1cvMnq3Qe3aFmipyeM4dMjP7hkK1h0cU9qtrFHosc0umWfbU4qZQquqpGctHz/TZtH5jQNQ+CncEslIsonsnrakaS9LGVseV6FkPrcJt8GS9KQrl6T6vkHNbtM9H5UvbyLkWJjfugJjZM939xhbr7qEQCL1coZrLFe7+s7LbrlvSqXVSukPJzJ6nMM141vim6H0+dhvJ7xdK+rInJQmT516ocMw/MGP5KjPiNlckOc9bz0JY6bO3ClPKx7AKKXKpdbdX6OB6mkJ53C97TqGK1DrnKdzpvE4hMH+hu+9bsPwRClkDKyRtJ+l77v6/LbbxWYVUvEYay7VeYj4NqY+D7IqBQG6OjedPeZ43OUbe89Ejb83szZLepDAwr3HSfb+kBe5+ZsbyX1Eo8/Z0hXzeBRZqXp9fFDDHyAgyP+Lur6rjtZu2UyVP/icKvTWLFA5YZ5fdySPadbHCRcXZCj3eCz3/tp4s3PraS6FX60kKB6GzW/RqycyeoBCUNIL///OcaXaT5fNyxfNSXGZp5MxsX1AI1r6Ud5Fh+VViPK930Mw+rPB9bC6DdXOjR7guqb/1gZKe6+4vbLF87MDE0iP0cy5iWqUJNQKzRkWOuyT9xksMiErW20XhdubbFXrtds1Z9iWpto24Le/ZAx+rTOH9VIU6939OPfd0hfrtf8hY/n6F3slPNnoni/arMbQrarKjnNdodUF2oEbevfpx0b6brHObMm51S9mDxioeH7+hEMRcJWmhpK+2Oj5adj39pFmj6/BbtcofURfiTcuU2uerbCM5Z5+kcAxeqeG00A9kfZ4Vv4+fUghKW806ml4n6rO3yLFdVT7DZL0xV0OLkRzz9tdwYP7jVsfK5PuypaR/eMEd+6Z1nqRwt3CFu99Ttn19my6i4TyrJ2nkLYei22h5f+yiK5EdbfTsWUW3EKNmtZIkdz/TzH4v6fUaDrY+4Tkl5jy/5vWheW/CzDIvIpLXy7r4qFSo3sz21nCP8d0KAUpmr2wiPXPnTlYihUchd2oPhdvMLXMhrUK+tMfXEF2pUJLox8m2XNLLk8897wKuse07kn9SqOebe6HoIycYeYLCQaTo+/tthWB3mkJv1q4anpktryf/lLwelLyNuPv85G7BJzX8HT67zp4zG1nO6iqFffC5LdaJri/t7suUpNk0Ai0zm58VaCmMIdgm2ca5nnMnpalNzfvbjgrHmaLvyiyFnpYXKHyGUkhPKJqWOHZq8SozfX5DcXXut1LonTw+6RjYzsyeWtQ7WbFd6cmO0rPUFp4Tcy7I8m6DL1SYtOd+hQueQ8ysVZByr+ImirESj5ttqHCueyT5V6anrbme/t6SBhXe3yiec/fBCgb+J7+f5KPv2BYtX2Wfj9qGhzEYb7Hy1SWqfB9f6vmpOnliP/uosV1VP0PPTpE7TyV6zC0MEH2Xwj65StK97v68FttbY2Esxz0K730P5c9yKzN7crKNbcKP1nIQY3Ixsk/TOqXSzfo2yPacahUt1vl+83PJgf7QgtXyBjPk5XRGX9FZuJ31WPpDNbNdzWw3d/9dzmquZJCJhZzRgxV2prxZiqYr9GD+JPmXO6o5cbvCQLSyQWaj9/upCr2ljVJ5H7WQ73RCznZ2V7gjMUfhyvNPCr3TuZPGNA5Wya2nAxSmRD1V0lXuntXTWyVfWh6qdXxP0vdsuFTe55WdO1pl0or0Qe7tybYaA3by7sY8QeFA+kSF/PonmtlKhV6Xf2SsssaTOrFWfma20zQ8SOii1OOvKWfwUNKjeUv6YGZmTzez7b31RA0tWaqcVdL2RjmrVik80QMTYwKtVA/p7pIOTYKCc7y4xmqVi/1PKNwyPU3SkV6u3OGpiptavMoU3o9r3pfc/e+Wk8+a9LKdL+n8VO/kUWZWdEeiSruUBLwDycPG41yxF2Tu3jIHN8N9Hle/e/PkYtyaHm9W0K7DkoDxxQoDup5i4Xb45Z6MAchYZ0VyHjlE4fh2laTXlOnRs6bKH8rPrf+WpEUWynem79hmjqOquM9HbSPZzqjvkA0PMMz63lX5PlZZJ/azn+FxY7vWi/gM0z3mDynkip/b6DFvtR2F1Ls9FQanvkLDM6YWte3rCp1E/6GQwz5VBUG2Qhrl5xQ6Sj6tcPxvZaHCgPsDFI6TuZOoNevbINuyb9M+ppDwnllH0UJ92g8r/F0+r5DS8Txlj7SXVGkkbemZglK+pJA/lfZnhWAz67ZQ3sEntxamu78udbV2lEJd5tPdPW8QwfaRQaYUctf3Sv18q6R3W8i/zQuy99DwwNIFSgaWKszuVphqkQRv8yXNN7PpyhlF7KEk3I9sOF/6QjMrzJeWJEuVykteewvlz2QXXbHAUxP0mNleJa+cvyVpvruvHzBjYea0/1V2ABU9M5uq9Z7F9mjG2tEjy1lJ8b0uVXq+k31jhkIP/mqFsoxFbvThcnrpvMvcCUQ845Z9CbFTi7viZ/pca2Zb+eg697kXARV6J6u0Swon8vTjVutHXZBZyHl+yN1/b2Zf0vBMrad5fpWnzLuZBdID3tKPzyto15kKlVsuV5joRxbKqx6gcIc1a53PKlyI/VDhHPFw8vxAVq+uVcitj71jqwr7fIVtSKH3eprKd0BV+T5WWafKZ1+6F7/KZ5iI6jFvstpDZZE1Cr3Gu5bY3i7u/mILJQ3fZqFCSZF17n6JmR3r7j8vcdyTQnrbKWZ2iLt/x0IqWCl9G2R79qxwmyt8AfPyu/5LIWjdRCGIfX2rQCt53ZhbiHlf0qI0loHmg4e7P2j5Jb2qBhz/NrO/KFzhP1P5I8claTcbnpa4odHLmmfAzMx9OH0h6a0q6vF5l0YOLP2ThfrEF0rKHGhmw5MB7KowQtuUTAaQs3xzvvRZanG7z+JL5d2m+NKNaWV7wZ+QDrAlyd1/aWZ5EwWlg7MyU9BLFXrPlN+j2aqkV1mbW3wpsyq9LrGB1vkKg4suVLjgeyB5/mmeP6AnXU4vfdfgGI0MDMcqdmrxKlN4f1Thb3qpmurcZy1csXeySruiq0xUuA1+nIYv7PdU6CzYQGFQ6+U5m7nCQmWF+1LPFaWurVMojVk4yLHJFyV93cyWKsx294CnpsLO8WKFY1BjfND6din77lV05Q+Lv2Mbvc9X2IbcfU5kB1SV72OVdWI/+9he/KoVmyr3mCukiW0k6bMK+8lXS6zTKG96n4Xa2Xmpug2/T7ZxadIZW2am2JXJOn+wMO5pkxLrSOrjIDuLu99rIf82z0PJQfdhM/u9uxcFGpIq3UJM905uo+HPoOi22wNmNtNH1ul8uvKvqKscfL6qMNL2t5K+r5CWkdtToWq1Vk+RdJ6ZnaThahkfSJ7P85g3VUhw94ctTLud5wSFyQA+3HjCQq7XF5Xd0xydL634UnnRpRtteLCRaWRJSfeckfAK390RAZyZzVTIvRyl+U5MSdE9KMrv0SwqnRXjd4ovZSbF5ynGBlr/Upge+unJv/UvpfyLq9ge2UrcfbPIVdb/Hc1sEy+YKCO1jdg691U6CL5pkdNLKxxzmj/3ZypUo8qrMhF7QTY51fYhTyYbK+o9VHzq2h8kHW0hJ/+KZPmrC5Zv1GSekxyHl5nZLRo+ruTlisdelFTJrY+6Y6tq+3zsNsILxnVARe8nFdeJ+uwr9OJX+Qwb7yEq7z3Vxp9ZKGO4QuECoEzn0lsVYp33SHqLwrG7aBsfSh5+xsy2cPd/lWjXwZJkYZbfXRXGsJTSz9VFmneYDRVydp7oOeXybGTpna2Uuq2bd/CxyJG0ZvY1SWe5+y/M7AaFg/wUSas8fzao7RVyk+7S8BXoEyUd5tmzSlap/tB8mzBdwi8rJeWyCkF241Zweic/193/WLD8bRo92t6UU2YsWSe24kverXbP612wyFJ5TeuWLd2Ye+Wf9bkn6zxVYTDj3Rq+kNlaYXaylqXwqrBQSmtDd7+/YJnnKnLmzsg2RE8VnawXW1qw7bOvJsehLyl8z49OPT7KS5TKi9hOenrsRj16mdmJ7n50xvKlS2im1km/bnqGycw690kv7ocV9qUvKzUrY0EHQZWpxatUmThNcSXmLpG0b/oiIQkgftzq2GkRpT6T5Scp7E8HKNxRvdbdM2v5Wkhz+4JCCsAXygR0se89o217qXXlj8xziuWUnq2yz8duI/ldugPqXCUdUJKU1QFVcT+JXie1bqnPPtWLf33quV0V7pTnje1Kb2MvlajYZJHV0JrWPVkhta5RsMC99aDEqQqpvZspHDdyz9vJ8nsrDE6dllq+8O9tZrsopDum1ylzB7qve7Kb0zIeVqg68ZOCdXaWdLjCl/VuhbzBcxWClkwVerae4+6NW6V3Nz4oM8utsuAht/gVFkb1bp2s91cLs6BlLf/Z5DW3U1JuyFtPShHbU7Ffi9cbxYanbv6cNeWaunvebfC8ALjoLkNe+kne89E5sAq90Z/OeJx5hWujSzfOU371joZX5gUoCgHIKEkvw6jvSovtRLGQj/ZBhfziBZLeJsnN7MpG0JbRriozd8bITV8q6J0LC8X1ukT1fFu1MlhPSP6tVAiGGuvkjVuo6mUKYyik0APUGGRUOJo/Uvp1j9TwDJP7KPs7XKV3cqZXSI+r0Ns2w+Nug39W0gXJHalGsPHW5PncNikydS1px2MW0mseVhh7VJTG9FFJg+kLdWs9GU3se290qMTk1sfesa2yz8duQwopoFI4R+6tVAeUCnq/OyXis4/uxa/wGVbNe294alZHWAs/UziX3tVodovlT5C0j7vfHbGN7ytMaHhnZNv6N8j2VFpGhC8p9F7v5+6PJD10H1ao7Xtk1goWfwtxfdDqI+tKb9CqcUlgvbGkt5lZ7ixoFiahOVVhYOHdkrZNgq53en4eaNTt06JeywLRuaZeLZ1hWxuekSwt7xZflXa9QwrpNCpXKi+6dKPiAxQlbWocGH9jZhuY2btUfOs81kcVek42Vkiv2d7d1yUH4cwg26rN3Bnjula9gzli8xSjgg0vN1Co2cEKMwS+TtL2Cqlk16i4HF8n7Jbar56detzyQibC9mV7iFI2t/h8/OgqE1JcYO7uV5rZ6xXudD472c4bPLvKT0NU6pqZvUahd/E5CpUVzpP0sawe1lS73pqsO2oymoJ2Rb13q5Zb/wFJ3zGzUXdsc5avss/HbkOK74Cqsp9Er1Phs48a21XxM0z3mJfOe7fhzIPbzOyDkv6opHOiYB9uuNfdj2+xTNovFc7BMW6QdE2VTqG+DbKtQu1jSbulf+fhlvAJNjqVIi12JO1NZvYWd/9hqq1vU0GOj8WP8v2ipPekrxwtlOA5UfkDMqN7KsaobXmn7j6rXa/dYPGl8tIpRI2ekHa0K7qyTAWrk33jEQtl/xoH9aIDUKULhnar0usSGWxETeKR/OJSJb22yf73WoV8w/ckbaxL3on9WTnt2izreSsevBpb575K7+S5iuz9rtjbViUw96bHrfIzMztzCtZ7scJ4oKJBiyPYyMlovqPQ8/9fLVaLfe9VKn/cpog7tlVU3EZsB9RmWS9StJ9U3LdiP/vYXvxKBRRULe+9sc/eoZD20egQKipXe1zy+3Vmdq5GBuajOq5SdxUnS/qVmf09+bnoQqaxzqaS/mpmjb9d6Y6Fvg2yVa328WQz26jpivVxKi67FxucHiXp0xbK1jUCrV8q/+AqxY/y3bT5ZOHuSy1MNZ6rwu3TWI1aoCZp6/TjOjdi8RPrpNu1Tcl2RZXKc/crzGwLhe/kkxROVD91938WbCM92DH9uCgvN31g/IukZ5U8MMaICs46JDp9SarU6xIbbERN4pFs/1iFvMQBSX9VOLm/1lunfEXJO7GXYSG3+HUarl+fd4s3ts59ld7J2Ek8KvW2xQbmFnI/j1Eoc3q9wrwAi8zseM+fgCs2de0Xkm5OltlRIYfbJH3e88e6RE9GU+GipMrdhcbvS92xVcV9PnIb0tjqS5fdT6qsE/vZx/biV/0MY6uhjco8SIL/AQ8Tf+VppIyWqrhU5a5ixTuRI/TtwMcGixhAYmavUijjd5qGB43NlZR7UEyC5ZdlBKeXeIupYCPew4YKo3z3U7jKe4akOZ4/6cuvFXoO072lpoJBeTaGwQoR7yO3lq9nTAQ0hu1coJyJdTx7oOjbNXyisdRjef7Ax7ypay/LChKaTrh3Kpxw364w8CgzH7/oIJ71PpJ1rldIcTJJX1GJgWOdYGb3KExcI4X98WKFNr7C3Wu9yIpsV9bgtI0lLc6742WjB++e06Lnu3kSjyEvmMQj6WncVCEAukEhVeQ6b6qyUwcz21fhuNK48DvPk9z/jGWflCy7t0LZq2dKeknRRZyZHazhOveN48qHJP3Q3UeV4Mzbf1q8h8uUEygWfIZVPveogWPJueE17r66aRs/Leg5i50q+1eeDEKzMBj7g5L+Iek7eX/H5HxysEId4jcrdLYtVMFkNBXe+6nKnsfAPX/wfdW6zKVV2UbsOb7iflJlnejPPll2VC++u9+esVz0Z5isd77ChFjNPeZfdvc5Oev8WNIh7r7KzD6tMNnLvxRKG34sZ51tFWbffDTpDD1E4ZxyetbfzcwOk/SjZBt7KIx3WadQxjIzVcrM9lGYxO7+pguZ47xk6cS+7cm2CgNIPJSPWaLQ27iLwknh9Z4qO5YhdpaqjRTqNe+h8AEPKMzU9lkPed1ZtlW4FdL4UPdSqHP6fHefnrH83xVmJUqfyLfWcOWUUSr0VFTxQ0lrPbmySwLPAYV8wNp4/MQ639XIGtaNixPX6MomDVGl8hQC7OYT7lmSfqr89190kZbXrp9KOlnhO3Nz8hrr1LqUXWkVDzzRM3d2SGyeYlQPqEVO4pFs/73JMlMUjkP/obC/T3L3XSu8x0wWch+fpdAT3OhU+HjyvT4pY5XbFfaVQ939AQvlSlvdJYmtc1+ld/I9CtUC7lc4xn9B4SLlSwXrRPe2Kf42+Lr0/p7aRm6+dAWPSpKFcrAD7v6b5OeidRYo5PD+TtLjFSomXKCCyWgU/96r5NZXrcvc7m3E3r2qsp9UWafKZx/Ti1/lM5Sq5b1vlgS/kxWC5ad7GOdTNE7gLA1/974n6VqFi4wfKHviuUM9KSSgcI6co5BOvFjD6WbNjvHhSiqnK3UhI6lUZ0DfBtmqVvtYHm7f55Z/yVg+Njj9hqSL3P0TjSfM7E0KQfE7ctb5VHqTyf/ba3gGsWZrJX3E3f+c2sZMFZx0YoOHii5RyC/9t5l9U+G9/EOhB/3QmrYhSbF1TaNrWCuMNP62mY0qlZezfJUT7nxJyxUGtDRKGrWyk0I1nOsVDhxb+HA1m7pUOfBUnrmzzWLzFGODjRdLoybxmKSQc5iZhmah7u3zFcpx7Zo8/WvVP/Bxf4UeusYx5S9mNqhwlyEryH6aQiD2fTP7p6QtzWxDT5UzzBBV596rDaj+tkKpw2kKF6y7SnpQIaDKC6KqVJmIDcx/Z2Yfk/Q/PnIg/XUF24hNXbszuZDbTcl5K+nVKxpIP83dT0weX2Rml3jryWhi33uV3PrKdZkjRG+jwjm+yn5SZZ2oz75CL36lik1eLe99ioVSfC+T9JtUB0RRjLom6cXeRKFqW6OWdV7aT6NzbwdJ93lyN7jFObjShUxaPwfZsQNIKqkQnD7Vm26TuvsCCxUgMvnIShYHKpQZvET5vT5bpAPs5DWWW8gJzlOpSH+kdUnwu5FCebqZ0vrbvbWxyIl10icYCzWsv21mhTWsPb5UXpUT7hMVgtb9FapN/FrhdldRULqpuzcupi6ycFu8blUOPNEzd3ZIbK9LVLDhw/nxGygMft1X4ftS1Mv6CYW7W6cp3Hatq8xhs/V3lRo8lAPL62G/XSH4PsmGS1KeaWYb+8hKSWk7mlnzrWVT61nZYqzxZBIOCwNx/548LkqvqdLbFhuYz1O46F6c7O+PKPQUfyFneSnMKOo5j7McojCo+TIfnqp9M0kfKdjG01KfiUnaofGz51c6in3v13l8bn3sHdsqorcRe46vsp9U3LdiP/vYXvwqn+F6ET3mUuhIvFDhruvh0vqOwaKUjMcs5IzvpeGB9FK4O5PlGgszNT9D0v8k29hMxTNOV7mIHaGfg+wqtY+rqFJ78gmeGvCW7FS5LAyEOEzh9sZihTJQhT0+ZjbVR6Ym5H3xGqrcPo01YGGylL01crDC42rchhRZ19Sq1bBu5OaWLZUXfcJ197WSLjazyxUCtM8r3L0ompiiygk0VpUDT5WZO9uuQq9LVLBhZm9U2G+nKvSy7ujuhccgz6k60gbPtuHKHw2mcEcnU3LSHPBQQecUM7tDUmbOZKJKnftYje+8SZqRevzUvBUq9rbFBubfViiptr6+edKL9r8KnSVZolLXkouiOyXta2ZvSNq12ItnfWz+TMp8FlUuSmLF3rHt1DaqnONj95PodSp89p24U1Ap793DPBmXND23XMmdYTOb5+7HNK32DoXv5WqFFFyZ2dOUM4O0ux9poR78Qz6c5mnJ68jMXuTuVzWt1riQSY9X2EzJhYyZ7djcodmsbwc+WuQAkjFs57Ksqz3Ln6VqNw3PfNdIM3iZQopCZikzM7tfocrA+QqjwtMD87JK1bxc4WBymkZOgnCc58+aFj1YIZaFgTLHKNzK/Zi7/y25Wn2rV6trXgszW6ORNawL/77JOutL5anELHNmdo7Ce07/fXeQdKK7Z55wLUz6kq6Q82MvHh8gM8vN4/ZqNceztjFJ4cDzYKMHxcy2VhiFn3mAtwozd3aahTKXByjUuL/fk3rCTctsr7jZV/8s6UqFwY7XmtmF7v7a9r2L8ixyYK2FqicvVLhguExhUoobJJ3i+fX3226s3/kyn3vT8mUHjuWdAzKfT373fEWkrllINXyLRg8sPdPdFxS9jyoi3vumrTqCCraRvmN7s8JMk8uL12rfNiqc46P3k4rrRH32SQAqDV+47aXwN8jsxa/6GSbxygJJn2z0mI/1mFclbjOzn7j7Pm3eRst1+rknu1Oierbc/XdmtpdGznx3nMJVcV694Kgg190vsVBlIj2As9UkCG3vqfAwMv0NTc8tV8EMaFWY2UJ3f33y+OueTFdvOdOqa2QN67JiS+U9ofkg7u63WHEKz0KFUm/3K/Q+HWJmhTlxdQXSRWrqPWuos0czWmyvS2wPqLvvaGFK3gOTE+ms5Bbnr7w437ITinrUs8atvNzdX5xcZN2uML3y39rTtPKqfOer9Laltlf6NnjsHUWPT107QvlpWLUH2WXfe8XgLPqObYe2EZsqU2U/qbJO7Gcf1Ys/hr99R3rMS5gauXz5ROuIdfo5yK5S+7iK6ODUQ47liAEFVpDPWuUk4vEDOG9TmycCsGoTBFXxhNTj9K3vzO97xcB08yRYMkmrVKKGaIUTbp2pOrXJ6UH5nJnl9p51IvivqFJFg5hAy91vUAjkGr1JB0n6tEqOTm+jdKqOK1R/OVzhzklWkL2BhXQvU7izNrXRO9bNnuyKoj/3CoH5cZIutJCSk76j2Jyjnt5GbOpaR9KwxnJREuEODd+x3VzSUaljal2pblW2EXuOr7KfVFkndlBx7NiuqtqRW18lAI5N06iS1tFynX5OF4mufTzG7ZW9jdaYpWjE05Le4u471N2uKmJvn0a87hsUP0FQle1cppCCM6BwMl3/OOu2X8VtHK8w2rxRKu98JaXyPKOGqFVI4UnW21vSG5V8tyQt9PyJLDrCzC7VyB4UWRjMemHNF0ttZ/E16DsRbHSUhTKMH5S0g0IqzLmeMUDYQkrZFI0uDfqIu9d9om6r2M89WSf6NriFmWH30fD+e2HRHUWLTF2zDqVhtSMFIGMbnUh1q7yNiHN89H5ScZ3bFPHZZ/Tif6fuOwXJdr6b+rHx/d1d0k6tOo4sDPRM167fyt3/bmZvdPfCEswZr5WZ5lOw/KkeWbKw1DGgj4PsdcoZQBL7h4zYZpmczrYfSKroZPBgERMEVXz99OQU6QusJ7n7zjVt4zyFWrPXK5Rpm+YtSuVVOOF+VGHw1okKPTBPlvRRSbd5ajBVp+Wl3RSk4/Qsi89TbHuw0SnJnZj3Kkx+cZK3KNVpZosUxhWMKg3qOeMKelXs556sEx2YV2hX1PkhY/ndFaop3Vvn+aQT7308KHmOj95PKq4T9dlb5NiusbIKufXJufuL7v5/ZnaIwnitvOoq6fWerfC9NEly9yvN7Onu/qeMZXdRKBk8LbV8YUxooZLWQU3byL0jNWLdPg6yowaQjGE7fdGz1aGeiuYJgn4r6WwvLklXZTtbKNQllsKV/gyFmTy3qisItKYBDxZqzdZaucbyB9Zc4TXNJlpFp3rPOiG216Wfgo2kI2K5pL+p6e6aZ+T8F3wfcwfy9aoqvW1VAvN2s5Dnn7aRQtWfH/nwxBt1bKfn3nunxJ7jq+wnFdeJ+uw71cE3lh5zC1Wqvi3peQoTS33OUzNt5qxzgcI8EnclT2XeTU4tf51C58KdGl6hMAYxs2sUZlBubKP036xvc7K9Qu3jijoxS1UndGKwQmOCoPMVeoClEhMEVXCmQn3szSX9QtISSZ/Juqodg06UyhswM/PUlXByodLtXO3mQYyNHpSuDmKswuPzFDtRy7dT5sWuYPGlQXtShc9d6kyJuSieUZUpeU9XKKT+1KXn3nsHVcnfj95PYteJ/ew7eKd8LLn171AYG3KcQqD+UrU+r5i7584zkuEGSdd43PwDt7n7mRHLr9e3QbZVrH1cQa+MpB2rTgQPRyb/t/v2yWR3/6EkmdnhCuXV6t5mlVqzsb4j6TwzO0nD5R4/qHpPnlXs1fTzRgpTW/9I4QA/bmT0urSqNtBPwUbsdzZ6IF+vqvC5d3Lg2Jh4mI667tccF++9TWLP8VX2k1r2rXZ89hWMpeTvQOMOepKSOU+tj1OrzGy+Qvziklp12j1H0l/NrJG64ll37ppsYWbXSmrM8unufkiLdST1d7pIdO3jitvpi9toYxmsELGNjuTJp9IZTNJcpVIb2pF71i7Jd+vxCuk1/0/SVZIWaWQx/Z7Q6EEZb6lSVfMUq+Qb9oPYcQW9qsrnPpbb4O1iowfSb6Qwrfw57v6/NW6n5957p1TM34/eTyqM2enIZ99pSUredA3nPv+1xfKjysO6+/drbtOoOQXKprn2c5DdqfyjtgenndTO4KGDefI9Obg0VvLdcoWDzaslNaqK1HpRUhczu2ocBtmxA80mbLDRT6ocIzo9cKyMjPfxsKQ/u/u/at5Oz733TunVc3ynPvtOMrOPK8zSPEshtfQRd285j0VMYJ6k4RwsaZvU8pl3DMzsNe7+UzN7p0aPWymV4tq3QXanjfeerU4HD0me/LcktSNPvu9YZDmidurXHpQyJnKwMdH1y8V7FRP5vTeM93P8eGBmv3L3FzYGfJrZWe5+cIt1ogJzM/s/hdTG90oaUrgjkZnTbWZHKHRuvVSjg+xSpaD7Nie7U6rk9vWotk8E0ME8+X7US1fDzTlyD0s6YTz3oEQYS74hxrGJEkxmmcjvvY/O8ePBo8n/q83sxZLKlNzdtzkwb7H8hu5+ipkd4u7fMbOi8qPfUk6Kq0pO9kdP9hj1S89WJ3oqOpUn3y9SPcbjOrccAMarfjnH9zILE/1IoYPvYYUKWidI+om7n9xi3UZwfWGyzjfc/dkFy5+lULjgvyVtLGlmXppjHSmuBNljxG208vhbxeHvBQDdxXG4/TKKIkihc6nl+CMze46kZZKeplDl6ifu/rMS2xxQSHNcli6dWLB8pRRXgmwAAAB0xVh6jJO5I96gUGrxm5Ke62GelObl3uHu380YU1RUUag5xfVChaovLYPy9a9BkA0AAIBui+0xNrMzFeZnOCTJzf551sBHM3uOu/8+685EQUWhMae4MvARAAAAXTHGoghbufu3zOyNLZablgymjOlZblk+sBWCbAAAAHTL3RrZY7yLpF3MrEyP8UozO1jS48zsgOS1sjRK4D5H0lRJv5P0XIWg/sqsFerIuSddBAAAAF1RcXKoRkWSqQo9zq9RqGl9kbvfXLCtC9z9damff+Lu+1RqeAn0ZAMAAKArKvYY36aRFUlWStpNoXe6qCLJVDN7s0LP+a4KQXrb0JMNAACAcaNqRRIz21xhcqGnSvqLpFPaOZEaQTYAAADGpZiKJGVL/tXWNoJsAAAAjBdVa1iXLflXF3KyAQAAMJ5UrUhStuRfLQiyAQAAMJ5U7X0uW/KvFqSLAAAAoG9VLfk35u0SZAMAAKBfmdk6jSz5Z8n/7u5FJf/GhHQRAAAA9LPdVaHk31jRkw0AAIAJIabk35i3RZANAACAflW15N+Yt0uQDQAAgH5lZms0suTf+uC3Rcm/MSEnGwAAAP2sbRPOFKEnGwAAAKjZQLcbAAAAAPQbgmwAAACgZgTZADAOmdljZnZ96t/2FV5jfzPbuQ3NA4AJj4GPADA+PeTuu47xNfaXdIGkm8quYGaT3X3tGLcLAH2PnmwA6BNm9jwzu8LMrjWzn5nZ1snzh5vZNWb2ezM7x8ymmtkLJe0r6cSkJ3wHM7vczGYn62xpZrcljw81sx+Z2WJJF5nZxmZ2avKa15nZfslyzzSz3yavd4OZ7didvwQAdB9BNgCMT49LpYqca2ZTJH1N0uvd/XmSTpU0L1l2kbs/392fozCl8Dvd/VeSzpd0tLvv6u63tNjenpLe7u4vk3SMpEvd/fmSXqoQqG8s6d2Svpr0sM+WdEe9bxkAxg/SRQBgfBqRLmJmz5L0LEkXm5kkTZJ0d/LrZ5nZ5yVtJunxkn5WYXsXu/u/ksd7S9rXzI5Kft5I0naSfi3pGDN7skJg/+cK2wGAvkCQDQD9wSTd6O57Zvzue5L2d/ffm9mhkvbKeY21Gr7DuVHT7x5s2tZB7n5z0zJLzew3kvaR9DMzO8zdLy3/FgCgf5AuAgD94WZJW5nZnpJkZlPM7JnJ7zaRdHeSUvLW1DoPJL9ruE3S85LHry/Y1s8kvd+SLnMze27y/9Mk3eruJymkouwypncEAOMYQTYA9AF3f1QhMP6imf1e0vWSXpj8+lOSfiPpYknLUqstkHR0MnhxB0n/Lek9ZvYrSVsWbO44SVMk3WBmf0x+lqSDJf3RzK6XNEvSaTW8NQAYl5hWHQAAAKgZPdkAAABAzQiyAQAAgJoRZAMAAAA1I8gGAAAAakaQDQAAANSMIBsAAACoGUE2AAAAUDOCbAAAAKBm/x+pN+B0poJaPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Feature_Selector.plot(which_features=\"accepted\",y_scale='log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if our base model improves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T17:36:48.109126Z",
     "iopub.status.busy": "2020-09-27T17:36:48.108098Z",
     "iopub.status.idle": "2020-09-27T17:36:48.825089Z",
     "shell.execute_reply": "2020-09-27T17:36:48.824092Z",
     "shell.execute_reply.started": "2020-09-27T17:36:48.109126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7246852764094144\n",
      "0.7216642754662841\n",
      "0.6194581280788177\n"
     ]
    }
   ],
   "source": [
    "subset = Feature_Selector.Subset()\n",
    "subset.drop(['NACCNMRI','DEMUN'], axis=1, inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(subset, df['target'], test_size=0.35, random_state=1)\n",
    "\n",
    "model_feat1 = RandomForestClassifier()\n",
    "#train model\n",
    "model_feat1.fit(X_train, y_train)\n",
    "y_pred = model_feat1.predict(X_test)\n",
    "print(model_feat1.score(X_test, y_test))\n",
    "print(precision_score(y_test,y_pred))\n",
    "print(recall_score(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T17:58:00.138019Z",
     "iopub.status.busy": "2020-09-27T17:58:00.137022Z",
     "iopub.status.idle": "2020-09-27T17:58:00.142009Z",
     "shell.execute_reply": "2020-09-27T17:58:00.142009Z",
     "shell.execute_reply.started": "2020-09-27T17:58:00.138019Z"
    }
   },
   "outputs": [],
   "source": [
    "### add genetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T17:58:02.041691Z",
     "iopub.status.busy": "2020-09-27T17:58:02.041691Z",
     "iopub.status.idle": "2020-09-27T17:58:02.765664Z",
     "shell.execute_reply": "2020-09-27T17:58:02.764678Z",
     "shell.execute_reply.started": "2020-09-27T17:58:02.041691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7252326217843459\n",
      "0.7195467422096318\n",
      "0.625615763546798\n"
     ]
    }
   ],
   "source": [
    "# subset['NACCNE4S']=df['NACCNE4S']\n",
    "# subset['NACCAPOE']=df['NACCAPOE']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(subset, df['target'], test_size=0.35, random_state=1)\n",
    "\n",
    "# model_feat1 = RandomForestClassifier()\n",
    "# #train model\n",
    "# model_feat1.fit(X_train, y_train)\n",
    "# y_pred = model_feat1.predict(X_test)\n",
    "# print(model_feat1.score(X_test, y_test))\n",
    "# print(precision_score(y_test,y_pred))\n",
    "# print(recall_score(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T00:46:55.572841Z",
     "iopub.status.busy": "2020-09-27T00:46:55.572841Z",
     "iopub.status.idle": "2020-09-27T00:46:55.576804Z",
     "shell.execute_reply": "2020-09-27T00:46:55.575812Z",
     "shell.execute_reply.started": "2020-09-27T00:46:55.572841Z"
    }
   },
   "source": [
    "## find which tests these featues are part of which tests and add the rest for engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T17:37:11.243361Z",
     "iopub.status.busy": "2020-09-27T17:37:11.243361Z",
     "iopub.status.idle": "2020-09-27T17:37:11.278243Z",
     "shell.execute_reply": "2020-09-27T17:37:11.277240Z",
     "shell.execute_reply.started": "2020-09-27T17:37:11.243361Z"
    }
   },
   "outputs": [],
   "source": [
    "dd=pd.read_csv(r\"..\\docs\\rdd_datadictionary_uds.csv\")\n",
    "import json\n",
    "with open('../data/processed/forms.txt') as json_file:\n",
    "    form_key = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T17:37:11.796812Z",
     "iopub.status.busy": "2020-09-27T17:37:11.796812Z",
     "iopub.status.idle": "2020-09-27T17:37:11.805758Z",
     "shell.execute_reply": "2020-09-27T17:37:11.804767Z",
     "shell.execute_reply.started": "2020-09-27T17:37:11.796812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Subject Demographics',\n",
       " 'Family History',\n",
       " 'Medications',\n",
       " 'Physical',\n",
       " 'CDR® Plus NACC FTLD',\n",
       " 'Functional Activities Questionnaire(FAQ)',\n",
       " 'Clinician Judgment of Symptoms',\n",
       " 'Neuropsychological Battery',\n",
       " 'Neuropsychological Battery',\n",
       " 'Neuropsychological Battery',\n",
       " 'Clinician Diagnosis']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forms_set=dd['Form'].loc[dd['VariableName'].isin(subset.columns)]\n",
    "forms_set.unique()\n",
    "equiv=[form_key[x] for x in forms_set.unique().tolist()]\n",
    "equiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T17:48:37.564071Z",
     "iopub.status.busy": "2020-09-27T17:48:37.564071Z",
     "iopub.status.idle": "2020-09-27T17:48:37.570061Z",
     "shell.execute_reply": "2020-09-27T17:48:37.569055Z",
     "shell.execute_reply.started": "2020-09-27T17:48:37.564071Z"
    }
   },
   "outputs": [],
   "source": [
    "#u_forms=forms_set.unique().tolist()\n",
    "u_forms=['b4','b7','c1c2','c1','c2']\n",
    "other_vars=dd['VariableName'].loc[dd['Form'].isin(u_forms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2020-09-27T17:58:44.611525Z",
     "iopub.status.busy": "2020-09-27T17:58:44.610551Z",
     "iopub.status.idle": "2020-09-27T17:58:44.669369Z",
     "shell.execute_reply": "2020-09-27T17:58:44.668363Z",
     "shell.execute_reply.started": "2020-09-27T17:58:44.611525Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEMORY</th>\n",
       "      <th>ORIENT</th>\n",
       "      <th>JUDGMENT</th>\n",
       "      <th>COMMUN</th>\n",
       "      <th>HOMEHOBB</th>\n",
       "      <th>PERSCARE</th>\n",
       "      <th>CDRSUM</th>\n",
       "      <th>CDRGLOB</th>\n",
       "      <th>COMPORT</th>\n",
       "      <th>CDRLANG</th>\n",
       "      <th>...</th>\n",
       "      <th>COGOTH2</th>\n",
       "      <th>NACCTMCI</th>\n",
       "      <th>MOCATOTS</th>\n",
       "      <th>TRAILARR</th>\n",
       "      <th>MOCAORDT</th>\n",
       "      <th>MOCAORMO</th>\n",
       "      <th>MOCAORYR</th>\n",
       "      <th>drug_count</th>\n",
       "      <th>UDSBENRS</th>\n",
       "      <th>NACCAPOE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18756</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18759</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18764</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18767</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18773</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5220 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MEMORY  ORIENT  JUDGMENT  COMMUN  HOMEHOBB  PERSCARE  CDRSUM  CDRGLOB  \\\n",
       "0         0.5     0.5       1.0     0.5       0.5       0.0     3.0      0.5   \n",
       "2         0.5     0.0       0.0     0.0       0.0       0.0     0.5      0.5   \n",
       "4         0.5     0.5       0.5     1.0       0.5       0.0     3.0      0.5   \n",
       "5         0.5     0.0       1.0     0.5       0.5       0.0     2.5      0.5   \n",
       "6         0.5     0.5       0.5     0.5       0.5       0.0     2.5      0.5   \n",
       "...       ...     ...       ...     ...       ...       ...     ...      ...   \n",
       "18756     0.0     0.0       0.0     0.0       0.0       0.0     0.0      0.0   \n",
       "18759     0.5     0.0       0.0     0.0       0.0       0.0     0.5      0.5   \n",
       "18764     0.0     0.0       0.0     0.0       0.0       0.0     0.0      0.0   \n",
       "18767     0.0     0.0       0.0     0.0       0.0       0.0     0.0      0.0   \n",
       "18773     0.0     0.0       0.0     0.0       0.0       0.0     0.0      0.0   \n",
       "\n",
       "       COMPORT  CDRLANG  ...  COGOTH2  NACCTMCI  MOCATOTS  TRAILARR  MOCAORDT  \\\n",
       "0         -4.0     -4.0  ...     -4.0         1      -4.0      -4.0      -4.0   \n",
       "2          0.0      0.0  ...      0.0         1      -4.0      97.0      -4.0   \n",
       "4          0.0      0.5  ...      0.0         2      -4.0       1.0      -4.0   \n",
       "5          0.5      0.5  ...      0.0         2      -4.0       0.0      -4.0   \n",
       "6          0.0      0.0  ...      0.0         4      -4.0       0.0      -4.0   \n",
       "...        ...      ...  ...      ...       ...       ...       ...       ...   \n",
       "18756     -4.0     -4.0  ...     -4.0         1      -4.0      -4.0      -4.0   \n",
       "18759      0.0      0.0  ...      0.0         3      -4.0       1.0      -4.0   \n",
       "18764      0.0      0.5  ...      0.0         3      -4.0      -4.0      -4.0   \n",
       "18767      0.0      0.0  ...      0.0         1      -4.0       0.0      -4.0   \n",
       "18773      0.0      0.0  ...      0.0         1      -4.0       0.0      -4.0   \n",
       "\n",
       "       MOCAORMO  MOCAORYR  drug_count  UDSBENRS  NACCAPOE  \n",
       "0          -4.0      -4.0           5      -4.0         1  \n",
       "2          -4.0      -4.0           7      -4.0         1  \n",
       "4          -4.0      -4.0           8      -4.0         1  \n",
       "5          -4.0      -4.0           2      -4.0         2  \n",
       "6          -4.0      -4.0           3      -4.0         2  \n",
       "...         ...       ...         ...       ...       ...  \n",
       "18756      -4.0      -4.0           5      -4.0         9  \n",
       "18759      -4.0      -4.0           9      -4.0         9  \n",
       "18764      -4.0      -4.0           3      -4.0         1  \n",
       "18767      -4.0      -4.0           7      -4.0         1  \n",
       "18773      -4.0      -4.0           6      -4.0         2  \n",
       "\n",
       "[5220 rows x 166 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broad_subset=df[df.columns.intersection(other_vars)]\n",
    "broad_subset=pd.concat([broad_subset, subset], axis=1, sort=False)\n",
    "broad_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's try the forest on this broad feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T17:58:49.809997Z",
     "iopub.status.busy": "2020-09-27T17:58:49.809997Z",
     "iopub.status.idle": "2020-09-27T17:58:50.706462Z",
     "shell.execute_reply": "2020-09-27T17:58:50.705469Z",
     "shell.execute_reply.started": "2020-09-27T17:58:49.809997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.722495894909688\n",
      "0.7213352685050798\n",
      "0.6120689655172413\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(broad_subset, df['target'], test_size=0.35, random_state=1)\n",
    "\n",
    "model_feat1 = RandomForestClassifier()\n",
    "#train model\n",
    "model_feat1.fit(X_train, y_train)\n",
    "y_pred = model_feat1.predict(X_test)\n",
    "print(model_feat1.score(X_test, y_test))\n",
    "print(precision_score(y_test,y_pred))\n",
    "print(recall_score(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save broad and subset features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T17:50:37.070557Z",
     "iopub.status.busy": "2020-09-27T17:50:37.070557Z",
     "iopub.status.idle": "2020-09-27T17:50:37.077512Z",
     "shell.execute_reply": "2020-09-27T17:50:37.076512Z",
     "shell.execute_reply.started": "2020-09-27T17:50:37.070557Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(broad_subset.columns, open('../models/01final_features_broad.sav', 'wb'))\n",
    "pickle.dump(subset.columns, open('../models/01final_features_res.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering + shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T17:50:51.425344Z",
     "iopub.status.busy": "2020-09-27T17:50:51.424347Z",
     "iopub.status.idle": "2020-09-27T17:50:51.429332Z",
     "shell.execute_reply": "2020-09-27T17:50:51.428344Z",
     "shell.execute_reply.started": "2020-09-27T17:50:51.424347Z"
    }
   },
   "outputs": [],
   "source": [
    "#import\n",
    "# Importing modules to create our layers and model.\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T17:50:53.574327Z",
     "iopub.status.busy": "2020-09-27T17:50:53.574327Z",
     "iopub.status.idle": "2020-09-27T17:50:53.605242Z",
     "shell.execute_reply": "2020-09-27T17:50:53.604271Z",
     "shell.execute_reply.started": "2020-09-27T17:50:53.574327Z"
    }
   },
   "outputs": [],
   "source": [
    "#normalize to 0-1\n",
    "scaler = MinMaxScaler()\n",
    "normalized = scaler.fit_transform(broad_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T17:50:58.818758Z",
     "iopub.status.busy": "2020-09-27T17:50:58.817760Z",
     "iopub.status.idle": "2020-09-27T17:50:58.873609Z",
     "shell.execute_reply": "2020-09-27T17:50:58.872608Z",
     "shell.execute_reply.started": "2020-09-27T17:50:58.818758Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the level of compression of the hidden layer. Basically, as the input is passed through the encoding layer, it will come out smaller if you want it to find salient features. If I choose num of columns for my encoding dimension, there would be a compression factor of 1, or nothing.\n",
    "encoding_dim = round(.75*subset.shape[1])\n",
    "input_dim = Input(shape=(subset.shape[1], ))\n",
    "# This is the size of the output. We want to generate 28 x 28 pictures in the end, so this is the size we're looking for. \n",
    "output_dim = subset.shape[1]\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_dim)\n",
    "decoded = Dense(output_dim, activation='sigmoid')(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T17:50:59.627521Z",
     "iopub.status.busy": "2020-09-27T17:50:59.627521Z",
     "iopub.status.idle": "2020-09-27T17:50:59.692321Z",
     "shell.execute_reply": "2020-09-27T17:50:59.691346Z",
     "shell.execute_reply.started": "2020-09-27T17:50:59.627521Z"
    }
   },
   "outputs": [],
   "source": [
    "# encoder\n",
    "autoencoder = Model(input_dim, decoded)\n",
    "# intermediate result\n",
    "encoder = Model(input_dim, encoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')#mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2020-09-27T17:51:01.019597Z",
     "iopub.status.busy": "2020-09-27T17:51:01.018599Z",
     "iopub.status.idle": "2020-09-27T17:51:48.712384Z",
     "shell.execute_reply": "2020-09-27T17:51:48.712384Z",
     "shell.execute_reply.started": "2020-09-27T17:51:01.019597Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3393 samples, validate on 1827 samples\n",
      "Epoch 1/550\n",
      "3393/3393 [==============================] - 0s 60us/step - loss: -17869.7519 - val_loss: -44655.0430\n",
      "Epoch 2/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -84974.6326 - val_loss: -140624.4265\n",
      "Epoch 3/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -218824.9756 - val_loss: -320678.0198\n",
      "Epoch 4/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -441821.3569 - val_loss: -594316.0878\n",
      "Epoch 5/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -758763.6078 - val_loss: -962761.3116\n",
      "Epoch 6/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -1168703.9139 - val_loss: -1423453.4754\n",
      "Epoch 7/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -1666594.3215 - val_loss: -1972384.8701\n",
      "Epoch 8/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -2253353.9421 - val_loss: -2610607.9007\n",
      "Epoch 9/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -2930593.8576 - val_loss: -3344069.1597\n",
      "Epoch 10/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -3701749.6141 - val_loss: -4170066.6461\n",
      "Epoch 11/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -4567160.7533 - val_loss: -5091184.7562\n",
      "Epoch 12/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -5521117.9704 - val_loss: -6100961.3300\n",
      "Epoch 13/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -6557177.2356 - val_loss: -7197238.1322\n",
      "Epoch 14/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -7674571.5561 - val_loss: -8360854.1938\n",
      "Epoch 15/550\n",
      "3393/3393 [==============================] - 0s 30us/step - loss: -8868870.2396 - val_loss: -9608917.3777\n",
      "Epoch 16/550\n",
      "3393/3393 [==============================] - 0s 30us/step - loss: -10139716.1194 - val_loss: -10925938.4483\n",
      "Epoch 17/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -11483560.8294 - val_loss: -12326968.4351\n",
      "Epoch 18/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -12900446.6446 - val_loss: -13794321.1839\n",
      "Epoch 19/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -14391091.3369 - val_loss: -15347369.6913\n",
      "Epoch 20/550\n",
      "3393/3393 [==============================] - 0s 30us/step - loss: -15974925.5809 - val_loss: -16992013.5255\n",
      "Epoch 21/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -17643504.1592 - val_loss: -18713713.0936\n",
      "Epoch 22/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -19384320.4262 - val_loss: -20509540.9819\n",
      "Epoch 23/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -21192899.6092 - val_loss: -22374213.8621\n",
      "Epoch 24/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -23067403.2361 - val_loss: -24306874.9557\n",
      "Epoch 25/550\n",
      "3393/3393 [==============================] - 0s 30us/step - loss: -25013488.1309 - val_loss: -26305192.2660\n",
      "Epoch 26/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -27023968.3006 - val_loss: -28369081.7701\n",
      "Epoch 27/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -29095649.7118 - val_loss: -30498098.6240\n",
      "Epoch 28/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -31231984.0389 - val_loss: -32679456.9097\n",
      "Epoch 29/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -33428343.4058 - val_loss: -34926452.2824\n",
      "Epoch 30/550\n",
      "3393/3393 [==============================] - 0s 30us/step - loss: -35682787.3103 - val_loss: -37246435.0936\n",
      "Epoch 31/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -37998790.9602 - val_loss: -39620337.5567\n",
      "Epoch 32/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -40373508.9620 - val_loss: -42040629.3990\n",
      "Epoch 33/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -42804498.1008 - val_loss: -44531231.7767\n",
      "Epoch 34/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -45293201.5597 - val_loss: -47079372.7619\n",
      "Epoch 35/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -47840384.7745 - val_loss: -49677417.1691\n",
      "Epoch 36/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -50442732.0354 - val_loss: -52331810.0624\n",
      "Epoch 37/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -53098172.0531 - val_loss: -55052144.3087\n",
      "Epoch 38/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -55811138.9461 - val_loss: -57821131.7504\n",
      "Epoch 39/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -58580042.2317 - val_loss: -60642561.6617\n",
      "Epoch 40/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -61403242.4332 - val_loss: -63512237.7537\n",
      "Epoch 41/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -64276175.8727 - val_loss: -66446892.9195\n",
      "Epoch 42/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -67205898.6242 - val_loss: -69436029.2151\n",
      "Epoch 43/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -70180613.5031 - val_loss: -72472859.0608\n",
      "Epoch 44/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -73210021.8568 - val_loss: -75552804.0066\n",
      "Epoch 45/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -76285163.2467 - val_loss: -78688175.2381\n",
      "Epoch 46/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -79408650.9956 - val_loss: -81877995.3235\n",
      "Epoch 47/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -82584273.6622 - val_loss: -85104518.4105\n",
      "Epoch 48/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -85806928.1415 - val_loss: -88386868.5846\n",
      "Epoch 49/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -89081629.5031 - val_loss: -91722673.3005\n",
      "Epoch 50/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -92406191.6888 - val_loss: -95109463.4745\n",
      "Epoch 51/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -95785057.1813 - val_loss: -98533910.3711\n",
      "Epoch 52/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -99206907.7843 - val_loss: -102019182.4368\n",
      "Epoch 53/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -102677710.4509 - val_loss: -105551030.1478\n",
      "Epoch 54/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -106191731.8126 - val_loss: -109139376.4992\n",
      "Epoch 55/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -109754567.5332 - val_loss: -112771039.3563\n",
      "Epoch 56/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -113365528.5447 - val_loss: -116436145.7997\n",
      "Epoch 57/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -117021657.5561 - val_loss: -120153068.8473\n",
      "Epoch 58/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -120721993.0681 - val_loss: -123916024.1051\n",
      "Epoch 59/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -124470628.3572 - val_loss: -127714015.8161\n",
      "Epoch 60/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -128263605.0363 - val_loss: -131571998.6601\n",
      "Epoch 61/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -132103615.5190 - val_loss: -135486060.7816\n",
      "Epoch 62/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -135991949.1706 - val_loss: -139420959.4483\n",
      "Epoch 63/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -139919394.8152 - val_loss: -143409646.3186\n",
      "Epoch 64/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -143890959.3634 - val_loss: -147450365.0575\n",
      "Epoch 65/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -147910100.0248 - val_loss: -151537773.4253\n",
      "Epoch 66/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -151969949.6233 - val_loss: -155657092.3350\n",
      "Epoch 67/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -156072615.7383 - val_loss: -159839067.0345\n",
      "Epoch 68/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -160220450.5747 - val_loss: -164051117.7406\n",
      "Epoch 69/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -164414742.2104 - val_loss: -168303841.8654\n",
      "Epoch 70/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -168652440.5305 - val_loss: -172593380.0460\n",
      "Epoch 71/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -172928696.8134 - val_loss: -176962506.5090\n",
      "Epoch 72/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -177250796.4067 - val_loss: -181353007.3957\n",
      "Epoch 73/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -181612848.2405 - val_loss: -185780359.5665\n",
      "Epoch 74/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -186015993.1388 - val_loss: -190252943.3432\n",
      "Epoch 75/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -190458093.0009 - val_loss: -194773568.1839\n",
      "Epoch 76/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -194951978.1149 - val_loss: -199302480.3941\n",
      "Epoch 77/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -199481773.9912 - val_loss: -203904848.4204\n",
      "Epoch 78/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -204056436.0743 - val_loss: -208547683.4154\n",
      "Epoch 79/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -208672097.9947 - val_loss: -213231597.2939\n",
      "Epoch 80/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -213326548.4421 - val_loss: -217961018.1938\n",
      "Epoch 81/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -218023543.0592 - val_loss: -222736045.8719\n",
      "Epoch 82/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -222762501.3050 - val_loss: -227539489.0509\n",
      "Epoch 83/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -227544438.1538 - val_loss: -232379174.5944\n",
      "Epoch 84/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -232365088.5517 - val_loss: -237299483.8752\n",
      "Epoch 85/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -237231832.0071 - val_loss: -242236236.2956\n",
      "Epoch 86/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -242143450.3413 - val_loss: -247187826.8374\n",
      "Epoch 87/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -247086888.9973 - val_loss: -252231289.4844\n",
      "Epoch 88/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -252075502.2034 - val_loss: -257294515.9672\n",
      "Epoch 89/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -257106934.0124 - val_loss: -262383990.9622\n",
      "Epoch 90/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -262172798.7409 - val_loss: -267545310.3186\n",
      "Epoch 91/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -267285288.6295 - val_loss: -272713908.4663\n",
      "Epoch 92/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -272431201.8532 - val_loss: -277951233.4713\n",
      "Epoch 93/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -277624876.4492 - val_loss: -283205653.8062\n",
      "Epoch 94/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -282860107.8833 - val_loss: -288508264.0394\n",
      "Epoch 95/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -288139352.7003 - val_loss: -293873850.2200\n",
      "Epoch 96/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -293457340.9726 - val_loss: -299265468.6897\n",
      "Epoch 97/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -298805953.4430 - val_loss: -304707915.6125\n",
      "Epoch 98/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -304210458.5676 - val_loss: -310157995.6650\n",
      "Epoch 99/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -309642842.4262 - val_loss: -315684429.1888\n",
      "Epoch 100/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -315117827.5933 - val_loss: -321219404.0854\n",
      "Epoch 101/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -320626662.7622 - val_loss: -326821518.1346\n",
      "Epoch 102/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -326179855.3917 - val_loss: -332453142.9622\n",
      "Epoch 103/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -331761687.7383 - val_loss: -338139803.3760\n",
      "Epoch 104/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -337399975.0168 - val_loss: -343825623.7504\n",
      "Epoch 105/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -343065774.0053 - val_loss: -349568583.5665\n",
      "Epoch 106/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -348779140.3855 - val_loss: -355379911.9343\n",
      "Epoch 107/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -354537809.4005 - val_loss: -361188263.1461\n",
      "Epoch 108/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -360323067.5296 - val_loss: -367064265.6158\n",
      "Epoch 109/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -366158454.8612 - val_loss: -372972409.4844\n",
      "Epoch 110/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -372028833.1600 - val_loss: -378923859.7570\n",
      "Epoch 111/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -377936350.5004 - val_loss: -384958245.4122\n",
      "Epoch 112/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -383902387.6640 - val_loss: -390972372.7028\n",
      "Epoch 113/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -389883264.8488 - val_loss: -397051811.1002\n",
      "Epoch 114/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -395927021.0716 - val_loss: -403159525.3596\n",
      "Epoch 115/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -401995027.3811 - val_loss: -409327814.7258\n",
      "Epoch 116/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -408107058.6737 - val_loss: -415508550.8834\n",
      "Epoch 117/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -414255339.6004 - val_loss: -421751703.8030\n",
      "Epoch 118/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -420454587.9257 - val_loss: -428014045.8982\n",
      "Epoch 119/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -426680850.6172 - val_loss: -434349485.1363\n",
      "Epoch 120/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -432949994.8364 - val_loss: -440696680.3021\n",
      "Epoch 121/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -439254893.0150 - val_loss: -447070774.8571\n",
      "Epoch 122/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -445593852.6614 - val_loss: -453531970.4696\n",
      "Epoch 123/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -451985475.0840 - val_loss: -459979879.5665\n",
      "Epoch 124/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -458395335.4129 - val_loss: -466533618.0230\n",
      "Epoch 125/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -464865569.3015 - val_loss: -473031800.7488\n",
      "Epoch 126/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -471357250.1786 - val_loss: -479626356.6502\n",
      "Epoch 127/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -477896625.1742 - val_loss: -486261448.5649\n",
      "Epoch 128/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -484477949.8780 - val_loss: -492914034.6010\n",
      "Epoch 129/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -491092482.3767 - val_loss: -499602590.4236\n",
      "Epoch 130/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -497753270.1821 - val_loss: -506374489.7471\n",
      "Epoch 131/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -504454048.0283 - val_loss: -513141390.8703\n",
      "Epoch 132/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -511182385.7683 - val_loss: -519974093.2939\n",
      "Epoch 133/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -517947437.4960 - val_loss: -526846333.0049\n",
      "Epoch 134/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -524766502.0831 - val_loss: -533737954.5222\n",
      "Epoch 135/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -531608165.5172 - val_loss: -540681716.1248\n",
      "Epoch 136/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -538489269.4182 - val_loss: -547668949.2808\n",
      "Epoch 137/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -545423353.4642 - val_loss: -554670408.1970\n",
      "Epoch 138/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -552379478.1256 - val_loss: -561721303.0148\n",
      "Epoch 139/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -559387457.5561 - val_loss: -568802625.6814\n",
      "Epoch 140/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -566419900.2653 - val_loss: -575941645.9770\n",
      "Epoch 141/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -573499721.1671 - val_loss: -583108546.7323\n",
      "Epoch 142/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -580622429.9912 - val_loss: -590325537.7340\n",
      "Epoch 143/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -587780910.3448 - val_loss: -597571610.3777\n",
      "Epoch 144/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -594984804.4421 - val_loss: -604883248.1314\n",
      "Epoch 145/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -602226643.0133 - val_loss: -612222145.9967\n",
      "Epoch 146/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -609505025.4713 - val_loss: -619602565.5698\n",
      "Epoch 147/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -616818614.2670 - val_loss: -627003533.3465\n",
      "Epoch 148/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -624168265.5066 - val_loss: -634427165.5304\n",
      "Epoch 149/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -631553269.3050 - val_loss: -641960041.4056\n",
      "Epoch 150/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -638992937.3652 - val_loss: -649448345.5369\n",
      "Epoch 151/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -646462819.5367 - val_loss: -657040394.4039\n",
      "Epoch 152/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -653967459.0274 - val_loss: -664660020.0197\n",
      "Epoch 153/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -661514979.0274 - val_loss: -672274031.7110\n",
      "Epoch 154/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -669101574.9036 - val_loss: -679936886.1215\n",
      "Epoch 155/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -676718691.9328 - val_loss: -687693272.8013\n",
      "Epoch 156/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -684396322.7445 - val_loss: -695445093.2020\n",
      "Epoch 157/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -692087068.4067 - val_loss: -703258558.4236\n",
      "Epoch 158/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -699832257.5844 - val_loss: -711088632.2233\n",
      "Epoch 159/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -707610276.2723 - val_loss: -718976474.6929\n",
      "Epoch 160/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -715428569.1247 - val_loss: -726890876.0066\n",
      "Epoch 161/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -723282212.2157 - val_loss: -734818799.0805\n",
      "Epoch 162/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -731175476.0601 - val_loss: -742830239.9475\n",
      "Epoch 163/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -739100687.0522 - val_loss: -750894695.4089\n",
      "Epoch 164/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -747071613.7365 - val_loss: -758959714.6798\n",
      "Epoch 165/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -755078289.7683 - val_loss: -767043706.0099\n",
      "Epoch 166/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -763114420.7958 - val_loss: -775187762.9688\n",
      "Epoch 167/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -771196772.0460 - val_loss: -783397729.4187\n",
      "Epoch 168/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -779321728.4527 - val_loss: -791624817.7077\n",
      "Epoch 169/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -787477529.5774 - val_loss: -799869823.2644\n",
      "Epoch 170/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -795669302.6065 - val_loss: -808201148.0066\n",
      "Epoch 171/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -803903841.7259 - val_loss: -816522995.7044\n",
      "Epoch 172/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -812175268.3289 - val_loss: -824849837.7143\n",
      "Epoch 173/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -820482031.5897 - val_loss: -833289229.3465\n",
      "Epoch 174/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -828833918.2458 - val_loss: -841744493.3990\n",
      "Epoch 175/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -837225275.0203 - val_loss: -850277102.2397\n",
      "Epoch 176/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -845651992.4456 - val_loss: -858798877.9507\n",
      "Epoch 177/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -854111713.7825 - val_loss: -867318973.5829\n",
      "Epoch 178/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -862599996.0389 - val_loss: -875951093.3859\n",
      "Epoch 179/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -871139788.6189 - val_loss: -884594565.7800\n",
      "Epoch 180/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -879709703.9788 - val_loss: -893295854.6601\n",
      "Epoch 181/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -888330820.4704 - val_loss: -902008111.3957\n",
      "Epoch 182/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -896982210.2069 - val_loss: -910775631.6585\n",
      "Epoch 183/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -905667001.3793 - val_loss: -919578701.1363\n",
      "Epoch 184/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -914398963.4377 - val_loss: -928395968.5255\n",
      "Epoch 185/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -923164287.1512 - val_loss: -937277488.2365\n",
      "Epoch 186/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -931981591.0875 - val_loss: -946199779.5205\n",
      "Epoch 187/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -940841253.8568 - val_loss: -955162794.4565\n",
      "Epoch 188/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -949719528.9691 - val_loss: -964154597.6223\n",
      "Epoch 189/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -958645225.1388 - val_loss: -973187346.7061\n",
      "Epoch 190/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -967600077.0150 - val_loss: -982290877.6880\n",
      "Epoch 191/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -976610462.4439 - val_loss: -991372902.9885\n",
      "Epoch 192/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -985635682.2918 - val_loss: -1000566941.3202\n",
      "Epoch 193/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -994718875.2184 - val_loss: -1009729899.1921\n",
      "Epoch 194/550\n",
      "3393/3393 [==============================] - 0s 31us/step - loss: -1003815906.5747 - val_loss: -1018968963.0476\n",
      "Epoch 195/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -1012969336.6437 - val_loss: -1028195241.0903\n",
      "Epoch 196/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -1022141081.4076 - val_loss: -1037516316.6897\n",
      "Epoch 197/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -1031372016.6083 - val_loss: -1046829764.2036\n",
      "Epoch 198/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -1040631257.1813 - val_loss: -1056206162.7061\n",
      "Epoch 199/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -1049936012.6189 - val_loss: -1065623362.1018\n",
      "Epoch 200/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1059266334.1043 - val_loss: -1075073936.3941\n",
      "Epoch 201/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1068649492.7675 - val_loss: -1084583740.2167\n",
      "Epoch 202/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -1078075884.6472 - val_loss: -1094094799.0279\n",
      "Epoch 203/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -1087517516.1662 - val_loss: -1103722264.9064\n",
      "Epoch 204/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -1097029240.9832 - val_loss: -1113280043.5074\n",
      "Epoch 205/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -1106543165.4536 - val_loss: -1122987526.9360\n",
      "Epoch 206/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1116128637.8497 - val_loss: -1132631812.2036\n",
      "Epoch 207/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -1125716738.8294 - val_loss: -1142396745.1429\n",
      "Epoch 208/550\n",
      "3393/3393 [==============================] - 0s 31us/step - loss: -1135365809.5703 - val_loss: -1152109640.5123\n",
      "Epoch 209/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -1145018944.5093 - val_loss: -1161940734.1084\n",
      "Epoch 210/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -1154739539.5225 - val_loss: -1171732418.8374\n",
      "Epoch 211/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -1164488037.4041 - val_loss: -1181621259.9803\n",
      "Epoch 212/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -1174292084.4562 - val_loss: -1191546739.8095\n",
      "Epoch 213/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -1184124170.7515 - val_loss: -1201480783.0279\n",
      "Epoch 214/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -1193977155.6782 - val_loss: -1211479559.9869\n",
      "Epoch 215/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -1203888250.7940 - val_loss: -1221486011.2709\n",
      "Epoch 216/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -1213841149.3970 - val_loss: -1231599712.8933\n",
      "Epoch 217/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -1223839682.4332 - val_loss: -1241666895.2381\n",
      "Epoch 218/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1233847710.8966 - val_loss: -1251852246.5944\n",
      "Epoch 219/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -1243902891.6852 - val_loss: -1262023933.2677\n",
      "Epoch 220/550\n",
      "3393/3393 [==============================] - 0s 35us/step - loss: -1253989574.6207 - val_loss: -1272215198.4762\n",
      "Epoch 221/550\n",
      "3393/3393 [==============================] - 0s 45us/step - loss: -1264117808.4385 - val_loss: -1282456401.3399\n",
      "Epoch 222/550\n",
      "3393/3393 [==============================] - 0s 33us/step - loss: -1274297137.0044 - val_loss: -1292771070.9491\n",
      "Epoch 223/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -1284506758.4509 - val_loss: -1303092027.9015\n",
      "Epoch 224/550\n",
      "3393/3393 [==============================] - 0s 20us/step - loss: -1294752141.8073 - val_loss: -1313458411.4023\n",
      "Epoch 225/550\n",
      "3393/3393 [==============================] - 0s 20us/step - loss: -1305034385.3156 - val_loss: -1323895499.0345\n",
      "Epoch 226/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -1315364145.4571 - val_loss: -1334358921.0378\n",
      "Epoch 227/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -1325740381.7082 - val_loss: -1344784115.3892\n",
      "Epoch 228/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -1336110816.6508 - val_loss: -1355382840.1182\n",
      "Epoch 229/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -1346560978.8435 - val_loss: -1365916935.1461\n",
      "Epoch 230/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1357035781.6587 - val_loss: -1376502545.8654\n",
      "Epoch 231/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -1367542001.8532 - val_loss: -1387128335.5534\n",
      "Epoch 232/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1378085707.8267 - val_loss: -1397822617.4319\n",
      "Epoch 233/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -1388692649.4218 - val_loss: -1408520925.1100\n",
      "Epoch 234/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1399308314.4828 - val_loss: -1419298213.4122\n",
      "Epoch 235/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1409966291.2962 - val_loss: -1430106687.8949\n",
      "Epoch 236/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1420659834.1149 - val_loss: -1440923390.5287\n",
      "Epoch 237/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1431394867.1547 - val_loss: -1451767155.1790\n",
      "Epoch 238/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -1442155505.4005 - val_loss: -1462665663.6847\n",
      "Epoch 239/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -1452969005.4960 - val_loss: -1473627494.9885\n",
      "Epoch 240/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -1463800023.8232 - val_loss: -1484630294.9097\n",
      "Epoch 241/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -1474688033.3864 - val_loss: -1495594558.2135\n",
      "Epoch 242/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -1485610038.3236 - val_loss: -1506665099.1396\n",
      "Epoch 243/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1496568232.8559 - val_loss: -1517734097.9704\n",
      "Epoch 244/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -1507558457.4925 - val_loss: -1528861224.5649\n",
      "Epoch 245/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1518589900.2794 - val_loss: -1540001628.6897\n",
      "Epoch 246/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1529659953.1176 - val_loss: -1551208528.9195\n",
      "Epoch 247/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1540781208.6720 - val_loss: -1562442240.6305\n",
      "Epoch 248/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1551917081.6905 - val_loss: -1573768112.9721\n",
      "Epoch 249/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1563106467.6499 - val_loss: -1585116004.8867\n",
      "Epoch 250/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -1574345244.7462 - val_loss: -1596495543.0673\n",
      "Epoch 251/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -1585621399.9929 - val_loss: -1607813307.4811\n",
      "Epoch 252/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -1596886751.6322 - val_loss: -1619312222.5813\n",
      "Epoch 253/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -1608233297.4854 - val_loss: -1630756559.2381\n",
      "Epoch 254/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -1619589491.5508 - val_loss: -1642262843.9015\n",
      "Epoch 255/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1631011615.0097 - val_loss: -1653746057.0378\n",
      "Epoch 256/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -1642444408.6437 - val_loss: -1665357209.4319\n",
      "Epoch 257/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -1653945269.7577 - val_loss: -1676983281.2874\n",
      "Epoch 258/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -1665471343.7029 - val_loss: -1688631735.9080\n",
      "Epoch 259/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -1677020484.8099 - val_loss: -1700378862.5550\n",
      "Epoch 260/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1688628248.8983 - val_loss: -1712112086.3842\n",
      "Epoch 261/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1700255391.0097 - val_loss: -1723877574.2003\n",
      "Epoch 262/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1711935249.0893 - val_loss: -1735646189.9245\n",
      "Epoch 263/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1723616309.0787 - val_loss: -1747597606.0427\n",
      "Epoch 264/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1735381676.5906 - val_loss: -1759370826.6141\n",
      "Epoch 265/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -1747138710.5217 - val_loss: -1771340353.1560\n",
      "Epoch 266/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -1758976037.5738 - val_loss: -1783344686.2397\n",
      "Epoch 267/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1770846320.6083 - val_loss: -1795291568.9721\n",
      "Epoch 268/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -1782740583.5544 - val_loss: -1807348193.7340\n",
      "Epoch 269/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -1794679303.0168 - val_loss: -1819467373.7143\n",
      "Epoch 270/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -1806653391.4483 - val_loss: -1831556825.9573\n",
      "Epoch 271/550\n",
      "3393/3393 [==============================] - 0s 34us/step - loss: -1818653389.9770 - val_loss: -1843679136.5780\n",
      "Epoch 272/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -1830696468.8240 - val_loss: -1855856007.3563\n",
      "Epoch 273/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -1842768636.1521 - val_loss: -1868144194.4171\n",
      "Epoch 274/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -1854898093.8355 - val_loss: -1880355677.1100\n",
      "Epoch 275/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -1867029357.6658 - val_loss: -1892679321.6420\n",
      "Epoch 276/550\n",
      "3393/3393 [==============================] - 0s 19us/step - loss: -1879233834.3271 - val_loss: -1905013763.7833\n",
      "Epoch 277/550\n",
      "3393/3393 [==============================] - 0s 20us/step - loss: -1891443501.8355 - val_loss: -1917376951.6979\n",
      "Epoch 278/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -1903709997.8355 - val_loss: -1929783150.3448\n",
      "Epoch 279/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1916027538.7869 - val_loss: -1942206723.1527\n",
      "Epoch 280/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -1928356542.0195 - val_loss: -1954691456.6305\n",
      "Epoch 281/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -1940738291.7772 - val_loss: -1967191304.4072\n",
      "Epoch 282/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -1953150790.3943 - val_loss: -1979823944.0920\n",
      "Epoch 283/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -1965616500.7958 - val_loss: -1992384016.3941\n",
      "Epoch 284/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1978094154.2423 - val_loss: -2005014309.6223\n",
      "Epoch 285/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -1990632057.7754 - val_loss: -2017741158.1478\n",
      "Epoch 286/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -2003201561.5774 - val_loss: -2030430058.3514\n",
      "Epoch 287/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -2015789924.6118 - val_loss: -2043184776.1970\n",
      "Epoch 288/550\n",
      "3393/3393 [==============================] - 0s 19us/step - loss: -2028436185.0681 - val_loss: -2055970486.4368\n",
      "Epoch 289/550\n",
      "3393/3393 [==============================] - 0s 30us/step - loss: -2041110888.1202 - val_loss: -2068794472.4598\n",
      "Epoch 290/550\n",
      "3393/3393 [==============================] - 0s 20us/step - loss: -2053839802.0584 - val_loss: -2081642674.2332\n",
      "Epoch 291/550\n",
      "3393/3393 [==============================] - 0s 20us/step - loss: -2066573122.9991 - val_loss: -2094572565.6486\n",
      "Epoch 292/550\n",
      "3393/3393 [==============================] - 0s 30us/step - loss: -2079368824.7569 - val_loss: -2107501335.5402\n",
      "Epoch 293/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -2092193844.3996 - val_loss: -2120476163.9934\n",
      "Epoch 294/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -2105055214.0053 - val_loss: -2133518173.9507\n",
      "Epoch 295/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -2117960079.0522 - val_loss: -2146561324.3481\n",
      "Epoch 296/550\n",
      "3393/3393 [==============================] - 0s 30us/step - loss: -2130905900.3643 - val_loss: -2159648214.1741\n",
      "Epoch 297/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -2143877254.1114 - val_loss: -2172758722.2069\n",
      "Epoch 298/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -2156879026.3625 - val_loss: -2185953075.4943\n",
      "Epoch 299/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -2169961212.6048 - val_loss: -2199134986.0887\n",
      "Epoch 300/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -2183036786.0796 - val_loss: -2212456923.8489\n",
      "Epoch 301/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -2196187722.4686 - val_loss: -2225667610.0624\n",
      "Epoch 302/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -2209340068.3289 - val_loss: -2239048953.6946\n",
      "Epoch 303/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -2222560664.2193 - val_loss: -2252368779.1396\n",
      "Epoch 304/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -2235786232.5305 - val_loss: -2265773540.2562\n",
      "Epoch 305/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -2249072597.2202 - val_loss: -2279180245.1232\n",
      "Epoch 306/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -2262375832.7851 - val_loss: -2292664135.4614\n",
      "Epoch 307/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -2275721893.2343 - val_loss: -2306220316.5846\n",
      "Epoch 308/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -2289106327.4271 - val_loss: -2319742678.8046\n",
      "Epoch 309/550\n",
      "3393/3393 [==============================] - 0s 33us/step - loss: -2302538614.8329 - val_loss: -2333288620.3481\n",
      "Epoch 310/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -2315995425.7259 - val_loss: -2346901605.7274\n",
      "Epoch 311/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -2329490453.9558 - val_loss: -2360608577.1560\n",
      "Epoch 312/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -2343046481.4854 - val_loss: -2374233658.0099\n",
      "Epoch 313/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -2356582445.2697 - val_loss: -2388012306.9163\n",
      "Epoch 314/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -2370202545.6835 - val_loss: -2401756077.1888\n",
      "Epoch 315/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -2383841476.0177 - val_loss: -2415582795.6650\n",
      "Epoch 316/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -2397522839.2007 - val_loss: -2429423439.4483\n",
      "Epoch 317/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -2411226432.7356 - val_loss: -2443316953.7471\n",
      "Epoch 318/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -2424981471.0663 - val_loss: -2457229155.2053\n",
      "Epoch 319/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -2438775487.2644 - val_loss: -2471094626.7849\n",
      "Epoch 320/550\n",
      "3393/3393 [==============================] - 0s 32us/step - loss: -2452590451.4377 - val_loss: -2485091458.3120\n",
      "Epoch 321/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -2466447301.6021 - val_loss: -2499189229.0837\n",
      "Epoch 322/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -2480372673.9805 - val_loss: -2513198401.5764\n",
      "Epoch 323/550\n",
      "3393/3393 [==============================] - 0s 30us/step - loss: -2494307841.1317 - val_loss: -2527362729.8259\n",
      "Epoch 324/550\n",
      "3393/3393 [==============================] - 0s 30us/step - loss: -2508300202.4403 - val_loss: -2541464362.0361\n",
      "Epoch 325/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -2522323784.2051 - val_loss: -2555684097.2611\n",
      "Epoch 326/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -2536402779.6711 - val_loss: -2569950350.5025\n",
      "Epoch 327/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -2550492443.3882 - val_loss: -2584172029.8982\n",
      "Epoch 328/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -2564606444.0813 - val_loss: -2598462675.4417\n",
      "Epoch 329/550\n",
      "3393/3393 [==============================] - 0s 30us/step - loss: -2578766943.0663 - val_loss: -2612784454.6207\n",
      "Epoch 330/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -2592959909.6870 - val_loss: -2627105910.1215\n",
      "Epoch 331/550\n",
      "3393/3393 [==============================] - 0s 31us/step - loss: -2607192151.1441 - val_loss: -2641561209.0640\n",
      "Epoch 332/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -2621450383.2785 - val_loss: -2656021004.6108\n",
      "Epoch 333/550\n",
      "3393/3393 [==============================] - 0s 30us/step - loss: -2635790163.5225 - val_loss: -2670427777.0509\n",
      "Epoch 334/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -2650113609.7896 - val_loss: -2684989588.3875\n",
      "Epoch 335/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -2664514479.1936 - val_loss: -2699512553.7209\n",
      "Epoch 336/550\n",
      "3393/3393 [==============================] - 0s 31us/step - loss: -2678923689.7613 - val_loss: -2714167974.4631\n",
      "Epoch 337/550\n",
      "3393/3393 [==============================] - 0s 31us/step - loss: -2693405341.9912 - val_loss: -2728724726.3317\n",
      "Epoch 338/550\n",
      "3393/3393 [==============================] - 0s 30us/step - loss: -2707894841.4925 - val_loss: -2743371424.5780\n",
      "Epoch 339/550\n",
      "3393/3393 [==============================] - 0s 38us/step - loss: -2722437190.6207 - val_loss: -2758065779.1790\n",
      "Epoch 340/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -2737015693.2414 - val_loss: -2772908453.6223\n",
      "Epoch 341/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -2751626041.2661 - val_loss: -2787702170.6929\n",
      "Epoch 342/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -2766287389.1989 - val_loss: -2802468262.8834\n",
      "Epoch 343/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -2780949028.8948 - val_loss: -2817391212.0328\n",
      "Epoch 344/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -2795673658.6242 - val_loss: -2832245360.6568\n",
      "Epoch 345/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -2810429908.0884 - val_loss: -2847162317.1363\n",
      "Epoch 346/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -2825218886.1680 - val_loss: -2862086975.4745\n",
      "Epoch 347/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -2840039310.1468 - val_loss: -2877173682.6535\n",
      "Epoch 348/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -2854912645.0928 - val_loss: -2892160645.6749\n",
      "Epoch 349/550\n",
      "3393/3393 [==============================] - 0s 20us/step - loss: -2869804728.9266 - val_loss: -2907199354.3251\n",
      "Epoch 350/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -2884738007.7100 - val_loss: -2922307470.9228\n",
      "Epoch 351/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -2899721576.5729 - val_loss: -2937482300.5320\n",
      "Epoch 352/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -2914754245.1494 - val_loss: -2952637356.7685\n",
      "Epoch 353/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -2929785429.3333 - val_loss: -2967891809.9442\n",
      "Epoch 354/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -2944889505.3864 - val_loss: -2983131304.9852\n",
      "Epoch 355/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -2960011416.1061 - val_loss: -2998486836.5452\n",
      "Epoch 356/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -2975207426.7162 - val_loss: -3013803350.1741\n",
      "Epoch 357/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -2990416898.9425 - val_loss: -3029178075.4286\n",
      "Epoch 358/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -3005645403.2184 - val_loss: -3044658607.7110\n",
      "Epoch 359/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -3020933570.4332 - val_loss: -3060121233.0246\n",
      "Epoch 360/550\n",
      "3393/3393 [==============================] - 0s 36us/step - loss: -3036258706.4474 - val_loss: -3075620131.7307\n",
      "Epoch 361/550\n",
      "3393/3393 [==============================] - 0s 31us/step - loss: -3051622967.0027 - val_loss: -3091071363.5731\n",
      "Epoch 362/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -3066979160.5022 - val_loss: -3106679738.6404\n",
      "Epoch 363/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3082409809.9381 - val_loss: -3122336053.3859\n",
      "Epoch 364/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -3097876470.2670 - val_loss: -3137921786.9557\n",
      "Epoch 365/550\n",
      "3393/3393 [==============================] - 0s 39us/step - loss: -3113364542.0195 - val_loss: -3153579701.5961\n",
      "Epoch 366/550\n",
      "3393/3393 [==============================] - 0s 32us/step - loss: -3128897570.8576 - val_loss: -3169232235.1921\n",
      "Epoch 367/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -3144451730.6737 - val_loss: -3185087688.9327\n",
      "Epoch 368/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -3160078028.8453 - val_loss: -3200800527.9737\n",
      "Epoch 369/550\n",
      "3393/3393 [==============================] - 0s 34us/step - loss: -3175678509.4960 - val_loss: -3216628911.2906\n",
      "Epoch 370/550\n",
      "3393/3393 [==============================] - 0s 31us/step - loss: -3191354756.1874 - val_loss: -3232482582.2791\n",
      "Epoch 371/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -3207048922.1998 - val_loss: -3248384655.3432\n",
      "Epoch 372/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -3222789373.7365 - val_loss: -3264254308.8867\n",
      "Epoch 373/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3238574311.3280 - val_loss: -3280258484.3350\n",
      "Epoch 374/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -3254415351.3988 - val_loss: -3296239667.7044\n",
      "Epoch 375/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3270277070.2034 - val_loss: -3312273365.5435\n",
      "Epoch 376/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -3286174272.2829 - val_loss: -3328339234.8900\n",
      "Epoch 377/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -3302100228.0743 - val_loss: -3344515291.4286\n",
      "Epoch 378/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -3318071404.1945 - val_loss: -3360649465.6946\n",
      "Epoch 379/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3334068767.2361 - val_loss: -3376824202.2989\n",
      "Epoch 380/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -3350099875.1972 - val_loss: -3393057752.0657\n",
      "Epoch 381/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -3366201166.3165 - val_loss: -3409306973.3202\n",
      "Epoch 382/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -3382344858.3696 - val_loss: -3425618392.9064\n",
      "Epoch 383/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3398476099.6782 - val_loss: -3442024539.2184\n",
      "Epoch 384/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3414701106.2493 - val_loss: -3458389510.7258\n",
      "Epoch 385/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3430919914.0442 - val_loss: -3474830408.3021\n",
      "Epoch 386/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -3447179710.8117 - val_loss: -3491252349.6880\n",
      "Epoch 387/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3463462792.2617 - val_loss: -3507745538.9425\n",
      "Epoch 388/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3479800692.5694 - val_loss: -3524182972.3218\n",
      "Epoch 389/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3496143075.7065 - val_loss: -3540793321.3005\n",
      "Epoch 390/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -3512570389.5031 - val_loss: -3557428817.5501\n",
      "Epoch 391/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -3529052331.1194 - val_loss: -3574023305.4581\n",
      "Epoch 392/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3545547137.9240 - val_loss: -3590806713.7997\n",
      "Epoch 393/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3562086759.8939 - val_loss: -3607374258.6535\n",
      "Epoch 394/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3578613240.7569 - val_loss: -3624273824.9984\n",
      "Epoch 395/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3595246578.1927 - val_loss: -3641012634.6929\n",
      "Epoch 396/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3611855823.5615 - val_loss: -3657827828.6502\n",
      "Epoch 397/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3628526573.6658 - val_loss: -3674667277.0312\n",
      "Epoch 398/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3645218159.3634 - val_loss: -3691589012.8079\n",
      "Epoch 399/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3661974648.8700 - val_loss: -3708506228.0197\n",
      "Epoch 400/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3678749820.2653 - val_loss: -3725551171.6782\n",
      "Epoch 401/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3695595535.8444 - val_loss: -3742530180.4138\n",
      "Epoch 402/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3712468257.7259 - val_loss: -3759515549.2151\n",
      "Epoch 403/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3729333214.7268 - val_loss: -3776678056.1445\n",
      "Epoch 404/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -3746271377.3156 - val_loss: -3793744589.1363\n",
      "Epoch 405/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3763237017.4642 - val_loss: -3810930700.1905\n",
      "Epoch 406/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -3780219489.5561 - val_loss: -3828122965.7537\n",
      "Epoch 407/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3797264018.9001 - val_loss: -3845350619.8489\n",
      "Epoch 408/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3814321687.3139 - val_loss: -3862597109.9113\n",
      "Epoch 409/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3831426649.6340 - val_loss: -3879855275.9278\n",
      "Epoch 410/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3848568596.3714 - val_loss: -3897192422.3580\n",
      "Epoch 411/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3865742563.9328 - val_loss: -3914653384.0920\n",
      "Epoch 412/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -3882956965.0080 - val_loss: -3932087453.6355\n",
      "Epoch 413/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3900217698.2352 - val_loss: -3949409882.3777\n",
      "Epoch 414/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3917496663.8232 - val_loss: -3966919299.1527\n",
      "Epoch 415/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -3934820799.7171 - val_loss: -3984501238.3317\n",
      "Epoch 416/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -3952195112.0637 - val_loss: -4002093834.0887\n",
      "Epoch 417/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -3969607716.4421 - val_loss: -4019663781.6223\n",
      "Epoch 418/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -3987030759.7807 - val_loss: -4037267467.7701\n",
      "Epoch 419/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -4004490347.9682 - val_loss: -4054956660.0197\n",
      "Epoch 420/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -4022020659.6074 - val_loss: -4072623567.2381\n",
      "Epoch 421/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -4039546365.9629 - val_loss: -4090375290.7455\n",
      "Epoch 422/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -4057134327.3988 - val_loss: -4108175032.1182\n",
      "Epoch 423/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -4074757130.6384 - val_loss: -4125971482.0624\n",
      "Epoch 424/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -4092415357.1706 - val_loss: -4143869088.5780\n",
      "Epoch 425/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -4110097376.5376 - val_loss: -4161813087.0016\n",
      "Epoch 426/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -4127855194.0866 - val_loss: -4179682958.0821\n",
      "Epoch 427/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -4145621689.6057 - val_loss: -4197680140.1905\n",
      "Epoch 428/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -4163451202.9991 - val_loss: -4215640724.8079\n",
      "Epoch 429/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -4181262734.1468 - val_loss: -4233764123.3235\n",
      "Epoch 430/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -4199146410.8930 - val_loss: -4251797356.4532\n",
      "Epoch 431/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -4217074588.6331 - val_loss: -4269872165.4122\n",
      "Epoch 432/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -4235002085.5172 - val_loss: -4288113490.3908\n",
      "Epoch 433/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -4253019703.2290 - val_loss: -4306273441.8391\n",
      "Epoch 434/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -4271052177.0893 - val_loss: -4324437355.1921\n",
      "Epoch 435/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -4289100204.2511 - val_loss: -4342806481.3399\n",
      "Epoch 436/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -4307214900.9655 - val_loss: -4361143522.1544\n",
      "Epoch 437/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -4325374436.1592 - val_loss: -4379433053.3202\n",
      "Epoch 438/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -4343527713.7259 - val_loss: -4397842729.6158\n",
      "Epoch 439/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -4361735931.6994 - val_loss: -4416300351.4745\n",
      "Epoch 440/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -4380011735.9363 - val_loss: -4434757112.0131\n",
      "Epoch 441/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -4398303108.8665 - val_loss: -4453226604.4532\n",
      "Epoch 442/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -4416611943.8939 - val_loss: -4471756034.9425\n",
      "Epoch 443/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -4434983230.2458 - val_loss: -4490264721.4450\n",
      "Epoch 444/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -4453364018.0230 - val_loss: -4508957986.0493\n",
      "Epoch 445/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -4471818771.6923 - val_loss: -4527593261.8194\n",
      "Epoch 446/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -4490290937.8886 - val_loss: -4546200900.5189\n",
      "Epoch 447/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -4508792401.9381 - val_loss: -4564961712.1314\n",
      "Epoch 448/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -4527373569.1317 - val_loss: -4583756452.7816\n",
      "Epoch 449/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -4545934134.5500 - val_loss: -4602593016.8539\n",
      "Epoch 450/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -4564561278.9814 - val_loss: -4621382854.4105\n",
      "Epoch 451/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -4583217563.5013 - val_loss: -4640233207.1724\n",
      "Epoch 452/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -4601915376.1556 - val_loss: -4659220685.9770\n",
      "Epoch 453/550\n",
      "3393/3393 [==============================] - 0s 20us/step - loss: -4620661605.8568 - val_loss: -4678169739.5599\n",
      "Epoch 454/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -4639422246.7056 - val_loss: -4697046553.2217\n",
      "Epoch 455/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -4658194907.7843 - val_loss: -4716173681.9179\n",
      "Epoch 456/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -4677066887.8090 - val_loss: -4735112779.6650\n",
      "Epoch 457/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -4695921469.7931 - val_loss: -4754244877.0312\n",
      "Epoch 458/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -4714844128.3112 - val_loss: -4773330600.1445\n",
      "Epoch 459/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -4733758530.0937 - val_loss: -4792538740.8604\n",
      "Epoch 460/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -4752743389.1424 - val_loss: -4811686857.3530\n",
      "Epoch 461/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -4771740920.0778 - val_loss: -4830928874.1412\n",
      "Epoch 462/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -4790782318.6844 - val_loss: -4850248245.8062\n",
      "Epoch 463/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -4809880389.9416 - val_loss: -4869479904.0525\n",
      "Epoch 464/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -4828985819.3316 - val_loss: -4888783155.7044\n",
      "Epoch 465/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -4848149973.4465 - val_loss: -4908176491.6125\n",
      "Epoch 466/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -4867344128.6790 - val_loss: -4927581004.0854\n",
      "Epoch 467/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -4886572042.8647 - val_loss: -4947057402.5353\n",
      "Epoch 468/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -4905876623.5049 - val_loss: -4966465489.7603\n",
      "Epoch 469/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -4925169070.9673 - val_loss: -4986071310.7126\n",
      "Epoch 470/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -4944540753.0327 - val_loss: -5005623691.1396\n",
      "Epoch 471/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -4963916156.7179 - val_loss: -5025304306.1281\n",
      "Epoch 472/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -4983354621.5102 - val_loss: -5044900035.0476\n",
      "Epoch 473/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -5002798535.4129 - val_loss: -5064504530.1806\n",
      "Epoch 474/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -5022278451.3811 - val_loss: -5084272300.3481\n",
      "Epoch 475/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -5041804509.8214 - val_loss: -5104021171.9146\n",
      "Epoch 476/550\n",
      "3393/3393 [==============================] - 0s 19us/step - loss: -5061398555.1618 - val_loss: -5123787003.3760\n",
      "Epoch 477/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -5081004740.9231 - val_loss: -5143653173.3859\n",
      "Epoch 478/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -5100665550.8824 - val_loss: -5163556387.3103\n",
      "Epoch 479/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -5120344256.3961 - val_loss: -5183482668.1379\n",
      "Epoch 480/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -5140063212.0813 - val_loss: -5203382768.8670\n",
      "Epoch 481/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -5159824141.3546 - val_loss: -5223376930.4696\n",
      "Epoch 482/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -5179598761.9876 - val_loss: -5243419519.3695\n",
      "Epoch 483/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -5199425473.9805 - val_loss: -5263382385.0772\n",
      "Epoch 484/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -5219241029.4889 - val_loss: -5283537130.5616\n",
      "Epoch 485/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -5239148215.3422 - val_loss: -5303529014.6470\n",
      "Epoch 486/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -5259059028.8806 - val_loss: -5323730460.5846\n",
      "Epoch 487/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -5279049687.2573 - val_loss: -5343962571.8752\n",
      "Epoch 488/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -5299067182.4014 - val_loss: -5364170261.8588\n",
      "Epoch 489/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -5319111649.2166 - val_loss: -5384445846.9097\n",
      "Epoch 490/550\n",
      "3393/3393 [==============================] - 0s 31us/step - loss: -5339184506.0018 - val_loss: -5404745316.8867\n",
      "Epoch 491/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -5359280198.6207 - val_loss: -5425196317.8456\n",
      "Epoch 492/550\n",
      "3393/3393 [==============================] - 0s 22us/step - loss: -5379465744.2971 - val_loss: -5445484473.3793\n",
      "Epoch 493/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -5399637976.6154 - val_loss: -5465953440.5780\n",
      "Epoch 494/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -5419900285.6233 - val_loss: -5486359942.0952\n",
      "Epoch 495/550\n",
      "3393/3393 [==============================] - 0s 21us/step - loss: -5440147322.9072 - val_loss: -5506868733.4778\n",
      "Epoch 496/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -5460451471.5049 - val_loss: -5527414937.8522\n",
      "Epoch 497/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -5480784279.8798 - val_loss: -5547960722.7061\n",
      "Epoch 498/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -5501151562.4686 - val_loss: -5568608541.8456\n",
      "Epoch 499/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -5521572889.3510 - val_loss: -5589217691.9540\n",
      "Epoch 500/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -5542035696.3820 - val_loss: -5609869581.8719\n",
      "Epoch 501/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -5562519047.6958 - val_loss: -5630628797.5829\n",
      "Epoch 502/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -5583051808.1415 - val_loss: -5651315112.5649\n",
      "Epoch 503/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -5603607934.0760 - val_loss: -5672176164.9918\n",
      "Epoch 504/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -5624220407.1724 - val_loss: -5693016418.7849\n",
      "Epoch 505/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -5644838401.8108 - val_loss: -5713844084.4401\n",
      "Epoch 506/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -5665482947.5650 - val_loss: -5734744644.0985\n",
      "Epoch 507/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -5686203861.8992 - val_loss: -5755655141.9376\n",
      "Epoch 508/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -5706939520.1132 - val_loss: -5776641662.9491\n",
      "Epoch 509/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -5727725839.6180 - val_loss: -5797705577.5107\n",
      "Epoch 510/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -5748545655.5119 - val_loss: -5818682812.7422\n",
      "Epoch 511/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -5769398343.5261 - val_loss: -5839731913.7734\n",
      "Epoch 512/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -5790264262.0548 - val_loss: -5860983729.8128\n",
      "Epoch 513/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -5811214070.7197 - val_loss: -5882099579.1658\n",
      "Epoch 514/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -5832173883.5296 - val_loss: -5903313914.9557\n",
      "Epoch 515/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -5853170754.9991 - val_loss: -5924534360.2759\n",
      "Epoch 516/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -5874208275.0133 - val_loss: -5945763414.5944\n",
      "Epoch 517/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -5895281663.0946 - val_loss: -5967134592.2102\n",
      "Epoch 518/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -5916406633.7047 - val_loss: -5988444745.9836\n",
      "Epoch 519/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -5937546508.4492 - val_loss: -6009824554.4565\n",
      "Epoch 520/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -5958714249.3935 - val_loss: -6031202244.3087\n",
      "Epoch 521/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -5979897094.1114 - val_loss: -6052696794.5878\n",
      "Epoch 522/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -6001130155.1194 - val_loss: -6074208707.4680\n",
      "Epoch 523/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -6022441114.8223 - val_loss: -6095656094.8966\n",
      "Epoch 524/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -6043754628.1874 - val_loss: -6117239476.7553\n",
      "Epoch 525/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -6065098981.0645 - val_loss: -6138846661.1494\n",
      "Epoch 526/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -6086517733.7436 - val_loss: -6160551825.0246\n",
      "Epoch 527/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -6107946285.9487 - val_loss: -6182145189.6223\n",
      "Epoch 528/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -6129416630.2104 - val_loss: -6203840479.2118\n",
      "Epoch 529/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -6150920397.5243 - val_loss: -6225638648.0131\n",
      "Epoch 530/550\n",
      "3393/3393 [==============================] - 0s 31us/step - loss: -6172465040.6366 - val_loss: -6247434824.3021\n",
      "Epoch 531/550\n",
      "3393/3393 [==============================] - 0s 24us/step - loss: -6194060798.6419 - val_loss: -6269214320.6568\n",
      "Epoch 532/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -6215640651.6004 - val_loss: -6291112501.8062\n",
      "Epoch 533/550\n",
      "3393/3393 [==============================] - 0s 23us/step - loss: -6237299453.5102 - val_loss: -6312920486.0427\n",
      "Epoch 534/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -6258951439.6180 - val_loss: -6334877484.9787\n",
      "Epoch 535/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -6280642759.6393 - val_loss: -6356818323.5468\n",
      "Epoch 536/550\n",
      "3393/3393 [==============================] - 0s 28us/step - loss: -6302387472.5234 - val_loss: -6378835143.2512\n",
      "Epoch 537/550\n",
      "3393/3393 [==============================] - 0s 30us/step - loss: -6324170564.1309 - val_loss: -6400760157.7406\n",
      "Epoch 538/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -6345970256.5800 - val_loss: -6422874713.9573\n",
      "Epoch 539/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -6367831088.4385 - val_loss: -6444980364.4007\n",
      "Epoch 540/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -6389711662.4014 - val_loss: -6467139741.2151\n",
      "Epoch 541/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -6411677390.4297 - val_loss: -6489282438.0952\n",
      "Epoch 542/550\n",
      "3393/3393 [==============================] - 0s 29us/step - loss: -6433627684.6684 - val_loss: -6511549139.8621\n",
      "Epoch 543/550\n",
      "3393/3393 [==============================] - 0s 31us/step - loss: -6455658654.4439 - val_loss: -6533748947.8621\n",
      "Epoch 544/550\n",
      "3393/3393 [==============================] - 0s 30us/step - loss: -6477728467.4094 - val_loss: -6556059800.1708\n",
      "Epoch 545/550\n",
      "3393/3393 [==============================] - 0s 33us/step - loss: -6499800703.6605 - val_loss: -6578468645.4122\n",
      "Epoch 546/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -6521931610.3130 - val_loss: -6600738310.7258\n",
      "Epoch 547/550\n",
      "3393/3393 [==============================] - 0s 27us/step - loss: -6544103992.5871 - val_loss: -6623241309.3202\n",
      "Epoch 548/550\n",
      "3393/3393 [==============================] - 0s 25us/step - loss: -6566331320.9266 - val_loss: -6645643119.3957\n",
      "Epoch 549/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -6588554318.3165 - val_loss: -6668222857.4581\n",
      "Epoch 550/550\n",
      "3393/3393 [==============================] - 0s 26us/step - loss: -6610818086.0265 - val_loss: -6690655271.5140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x267eac04f08>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(subset, df['target'], test_size=0.35, random_state=1)\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=550,\n",
    "                batch_size=60,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit the  forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T17:51:48.798143Z",
     "iopub.status.busy": "2020-09-27T17:51:48.798143Z",
     "iopub.status.idle": "2020-09-27T17:51:51.180480Z",
     "shell.execute_reply": "2020-09-27T17:51:51.179509Z",
     "shell.execute_reply.started": "2020-09-27T17:51:48.798143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533661740558292\n",
      "0.4971014492753623\n",
      "0.4224137931034483\n"
     ]
    }
   ],
   "source": [
    "encoded_X_train = encoder.predict(X_train)\n",
    "encoded_X_val = encoder.predict(X_test)\n",
    "\n",
    "model_feat1 = RandomForestClassifier()\n",
    "#train model\n",
    "model_feat1.fit(encoded_X_train, y_train)\n",
    "y_pred = model_feat1.predict(encoded_X_val)\n",
    "print(model_feat1.score(encoded_X_val, y_test))\n",
    "print(precision_score(y_test,y_pred))\n",
    "print(recall_score(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sucessful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AD",
   "language": "python",
   "name": "ad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
